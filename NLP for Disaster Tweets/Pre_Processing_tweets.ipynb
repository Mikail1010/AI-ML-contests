{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-Processing tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CD-VzmnuYVS7",
        "RKiQALnkQi0z",
        "HFjD_C8Bd1Se",
        "erFA7A7bY-dd",
        "DpNTHisMZCVF",
        "u-ypA4zWwcUU",
        "BW6_3w1oBAij"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD-VzmnuYVS7"
      },
      "source": [
        "##Install Pre req from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvLdTlR_5zmm"
      },
      "source": [
        "Download the required datasets from the Kaggle repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f9FO_opJRYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74292da1-16e7-4a07-f33e-f5283da0787d"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR2uE98Ldhuc"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMDzcnWlbJwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca9c975-59bc-4b66-fb78-6e3fec9b3976"
      },
      "source": [
        "cd /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cf2HBAncOQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893d4e62-0947-40df-e6c7-9488bb518dec"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glAEPUhd59Ht"
      },
      "source": [
        "Upload the json file for Kaggle authorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM2PGrP3bctH"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU3ZJTk_VgLX"
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scI7yYyEVgEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bfd8dc8-6bfd-4318-eb4d-1bd09150d243"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcdjZMHkcBTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e91f95-724e-48f1-e6c7-87dfeacd1cba"
      },
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/411k [00:00<?, ?B/s]\n",
            "100% 411k/411k [00:00<00:00, 27.3MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/22.2k [00:00<?, ?B/s]\n",
            "100% 22.2k/22.2k [00:00<00:00, 21.1MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/965k [00:00<?, ?B/s]\n",
            "100% 965k/965k [00:00<00:00, 63.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKiQALnkQi0z"
      },
      "source": [
        "#Import required libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t5Hf5yD0lbQ",
        "outputId": "08638f58-1368-4505-b2fa-f487d9e4b57d"
      },
      "source": [
        "!pip install autocorrect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autocorrect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/a8/1fc332535fc26db807fa48bdb54070355b83a36c797451c3d563bc190fa8/autocorrect-2.3.0.tar.gz (621kB)\n",
            "\r\u001b[K     |▌                               | 10kB 16.1MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30kB 23.2MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 8.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 624kB 8.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.3.0-cp36-none-any.whl size=621588 sha256=5a32ee73785698eece3d3c6ec44cdcd807b6ffb9b738324d8294bf287597f282\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/1c/30/6b0199afbd20eef5959f5eaa0ead86aeef84391740482b2279\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD3cGJ-ZQT0Y"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "import re\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "from autocorrect import Speller\r\n",
        "\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "import json\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "pd.options.display.max_columns = None\r\n",
        "pd.options.display.max_rows = None\r\n",
        "pd.options.display.width = None\r\n",
        "pd.options.display.max_colwidth = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFjD_C8Bd1Se"
      },
      "source": [
        "#Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZrRZR8QfNYC"
      },
      "source": [
        "Tweets = pd.read_csv(\"/content/train.csv\", encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9EUyAx0Q1hj"
      },
      "source": [
        "#Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sClDhJ_e6z_d"
      },
      "source": [
        "Some helper functions for preprocessing the tweets are defined here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QJGpfao6-xN"
      },
      "source": [
        "Load the dictionaries from the GitHub repositiory to process contracted words and words with repeated characters.\r\n",
        "\r\n",
        "**Contracted words**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Eg  I've  = I have\r\n",
        "\r\n",
        "**Repeated characters words**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Eg  goooaaalll  = goal\r\n",
        "\r\n",
        "coooool     = cool\r\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlYbt7S7ozzR",
        "outputId": "f6caa3c5-5433-4ae3-e56d-901ddbdd3239"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/contractions_dict.json\r\n",
        "!wget https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/repetitions_dict.json\r\n",
        "!wget https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/emoticons_dict.json\r\n",
        "!wget https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/html_tags_dict.json\r\n",
        "!wget https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/chat_words_dict.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-17 21:52:06--  https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/contractions_dict.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2825 (2.8K) [text/plain]\n",
            "Saving to: ‘contractions_dict.json.1’\n",
            "\n",
            "\rcontractions_dict.j   0%[                    ]       0  --.-KB/s               \rcontractions_dict.j 100%[===================>]   2.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 21:52:06 (51.9 MB/s) - ‘contractions_dict.json.1’ saved [2825/2825]\n",
            "\n",
            "--2021-02-17 21:52:06--  https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/repetitions_dict.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217 [text/plain]\n",
            "Saving to: ‘repetitions_dict.json.1’\n",
            "\n",
            "repetitions_dict.js 100%[===================>]     217  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 21:52:06 (9.13 MB/s) - ‘repetitions_dict.json.1’ saved [217/217]\n",
            "\n",
            "--2021-02-17 21:52:06--  https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/emoticons_dict.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 481 [text/plain]\n",
            "Saving to: ‘emoticons_dict.json.1’\n",
            "\n",
            "emoticons_dict.json 100%[===================>]     481  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 21:52:06 (22.1 MB/s) - ‘emoticons_dict.json.1’ saved [481/481]\n",
            "\n",
            "--2021-02-17 21:52:06--  https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/html_tags_dict.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83 [text/plain]\n",
            "Saving to: ‘html_tags_dict.json.1’\n",
            "\n",
            "html_tags_dict.json 100%[===================>]      83  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 21:52:06 (4.15 MB/s) - ‘html_tags_dict.json.1’ saved [83/83]\n",
            "\n",
            "--2021-02-17 21:52:06--  https://raw.githubusercontent.com/Mikail1010/AI-ML-contests/main/NLP%20for%20Disaster%20Tweets/Helper%20dicts/chat_words_dict.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1823 (1.8K) [text/plain]\n",
            "Saving to: ‘chat_words_dict.json.1’\n",
            "\n",
            "chat_words_dict.jso 100%[===================>]   1.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 21:52:06 (7.51 MB/s) - ‘chat_words_dict.json.1’ saved [1823/1823]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYPErxHAvVzs",
        "outputId": "1faaf0ef-f4c3-4498-e4d5-8d35a09d0921"
      },
      "source": [
        "with open('contractions_dict.json', 'r') as fp:\r\n",
        "    contractions_dict = json.load(fp)\r\n",
        "with open('repetitions_dict.json', 'r') as fp:\r\n",
        "    repetitions_dict = json.load(fp)\r\n",
        "with open('emoticons_dict.json', 'r') as fp:\r\n",
        "    emoticons_dict = json.load(fp)\r\n",
        "with open('html_tags_dict.json', 'r') as fp:\r\n",
        "    html_tags_dict = json.load(fp)\r\n",
        "html_tags_list = (html_tags_dict['HTML tags']).split(',')\r\n",
        "with open('chat_words_dict.json', 'r') as fp:\r\n",
        "    chat_words_dict = json.load(fp)\r\n",
        "\r\n",
        "print('Contracted Words =', len(contractions_dict), 'Repetition Letter Words =',len(repetitions_dict), 'Emoticons =',len(emoticons_dict),\r\n",
        "      'html_tags =', len(html_tags_list), 'Chat Words =', len(chat_words_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contracted Words = 106 Repetition Letter Words = 13 Emoticons = 19 html_tags = 8 Chat Words = 66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX8C_6aE8CFf"
      },
      "source": [
        "Helper functions for basic text processing, tweet processing, extracting features and tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUzOsh66sUSN",
        "outputId": "a389eca0-72ac-44ff-d732-33ecf17471f7"
      },
      "source": [
        "nltk.download('wordnet')\r\n",
        "nltk.download('stopwords')\r\n",
        "stopwords.words('english')\r\n",
        "tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+')\r\n",
        "emoji_pattern = re.compile(\"[\"\r\n",
        "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
        "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
        "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
        "                        u\"\\U00002702-\\U000027B0\"\r\n",
        "                        u\"\\U000024C2-\\U0001F251\"\r\n",
        "                        \"]+\", flags=re.UNICODE)\r\n",
        "chat_words = re.compile('\\\\b' + '\\\\b|\\\\b'.join(list(chat_words_dict.keys())))\r\n",
        "spell = Speller(lang='en')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0jYxxEwxgNd"
      },
      "source": [
        "def BasicTextProcessing(text, remove_url, lower_text_case,\r\n",
        "                        remove_nos, remove_punctutation, remove_html_tags, convert_html_text,\r\n",
        "                        chat_lingo_replace\r\n",
        "                        ):\r\n",
        "  # Removing line breaks, html tags, certain unicode symbols\r\n",
        "  # To remove url, nos and punctutation and convert to lower case if necessary\r\n",
        "  if remove_url:\r\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\r\n",
        "\r\n",
        "  if lower_text_case:\r\n",
        "    text = text.lower()\r\n",
        "  if chat_lingo_replace:\r\n",
        "    for keys,vals in chat_words_dict.items():\r\n",
        "      text = re.sub('\\\\b' + keys + '\\\\b', vals, text)\r\n",
        "\r\n",
        "  text = re.sub('\\\\n', '', text)\r\n",
        "  text = re.sub('ûª', \"'\", text)\r\n",
        "  text = re.sub('&amp;', 'and', text)\r\n",
        "  text = re.sub('&lt;', '', text)\r\n",
        "  text = re.sub('&gt;', '', text)\r\n",
        "  if remove_nos:\r\n",
        "    text = re.sub('\\d+', '', text)\r\n",
        "  if remove_html_tags:\r\n",
        "    for tag in html_tags_list:\r\n",
        "      text = re.sub(tag, '', text)\r\n",
        "  if convert_html_text:\r\n",
        "      text = BeautifulSoup(text, \"lxml\").text\r\n",
        "\r\n",
        "  return text\r\n",
        "\r\n",
        "def RemovePunctutation(text):\r\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\r\n",
        "  return text\r\n",
        "\r\n",
        "def SpellCheck(text):\r\n",
        "    corrected_text = []\r\n",
        "    misspelled_text = text.split()\r\n",
        "    for word in text.split():\r\n",
        "        corrected_text.append(spell(word))\r\n",
        "    return \" \".join(corrected_text)\r\n",
        "        \r\n",
        "#   text = re.sub('\\[.*?\\]', '', text)\r\n",
        "#   text = re.sub('<.*?>+', '', text)\r\n",
        "#   text = re.sub('\\w*\\d\\w*', '', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3T7cJGJxWWl"
      },
      "source": [
        "# To extract URLs as a seperate feature\r\n",
        "def ExtractURL(text):\r\n",
        "  match = re.findall('https?://\\S+|www\\.\\S+', text)\r\n",
        "  if match == []:\r\n",
        "    url = np.nan\r\n",
        "  else:\r\n",
        "    url = match\r\n",
        "  return url\r\n",
        "\r\n",
        "# To extract Hashtags as a seperate feature\r\n",
        "def Extracthashtag(text):\r\n",
        "  match = re.findall('#\\S+', text)\r\n",
        "  if match == []:\r\n",
        "    hashtag = np.nan\r\n",
        "  else:\r\n",
        "    hashtag = match\r\n",
        "    for idx, i in enumerate(hashtag):\r\n",
        "      hashtag[idx] = re.sub('[%s]' % re.escape(string.punctuation), '', i)\r\n",
        "  return hashtag\r\n",
        "\r\n",
        "# To extract Mentioned Names as a seperate feature\r\n",
        "def ExtractMentioned(text):\r\n",
        "  match = re.findall('@\\S+', text)\r\n",
        "  if match == []:\r\n",
        "    mentioned = np.nan\r\n",
        "  else:\r\n",
        "    mentioned = match\r\n",
        "    for idx, i in enumerate(mentioned):\r\n",
        "      mentioned[idx] = re.sub('[@]' , '', i)\r\n",
        "  return mentioned\r\n",
        "\r\n",
        "# To extract Emojis as a seperate feature\r\n",
        "def ExtractEmoji(text):\r\n",
        "  match = re.findall('@\\S+', text)\r\n",
        "  if match == []:\r\n",
        "    emoji = np.nan\r\n",
        "  else:\r\n",
        "    emoji = match\r\n",
        "  return emoji\r\n",
        "\r\n",
        "# To extract Emoticons as a seperate feature\r\n",
        "def ExtractEmoticons(text):\r\n",
        "  match = []\r\n",
        "  for key, value in emoticons_dict.items():\r\n",
        "    if key in text:\r\n",
        "      match.append(key)\r\n",
        "  if match == []:\r\n",
        "    emoticons = np.nan\r\n",
        "  else: \r\n",
        "    emoticons = [emoticons_dict[i] for i in match]\r\n",
        "  return emoticons\r\n",
        "\r\n",
        "def chat_words_dict_E(text):\r\n",
        "  match = re.findall(chat_words, text)\r\n",
        "  # print(match)\r\n",
        "  if match == []:\r\n",
        "    chat = np.nan\r\n",
        "  else: \r\n",
        "    chat = [chat_words_dict[i] for i in match]\r\n",
        "  return chat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSOomzbqQeh9"
      },
      "source": [
        "# To perfrom tweets specific text processing\r\n",
        "def FixCommonTweetErrors(text, remove_hashtag, remove_mentioned, remove_emoji, remove_emoticons):\r\n",
        "  # To expand contracted words\r\n",
        "  def Expand_Contractions(text):\r\n",
        "    for keys,vals in contractions_dict.items():\r\n",
        "      text = re.sub(keys, vals, text)\r\n",
        "    return text\r\n",
        "  # To contract words with repeated letters\r\n",
        "  def Contract_Repetitions(text):\r\n",
        "    for keys,vals in repetitions_dict.items():\r\n",
        "      text = re.sub(keys, vals, text)\r\n",
        "    return text\r\n",
        "  def remove_emoticons(text):\r\n",
        "    for keys,vals in emoticons_dict.items():\r\n",
        "      text = re.sub(keys, vals, text)\r\n",
        "    return text\r\n",
        "  # To remove hashtaged words from text if necessary\r\n",
        "  if remove_hashtag:\r\n",
        "    text = re.sub('#\\S+', '', text)\r\n",
        "  if remove_mentioned:\r\n",
        "    text = re.sub('@\\S+', '', text)\r\n",
        "  if remove_emoji:\r\n",
        "    text = emoji_pattern.sub(r'', text)\r\n",
        "  if remove_emoticons:\r\n",
        "    text = Contract_Repetitions(text)\r\n",
        "\r\n",
        "\r\n",
        "  text = Contract_Repetitions(text)\r\n",
        "  text = Expand_Contractions(text)\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaGyhsKXxokl"
      },
      "source": [
        "# To remove stopwords if necessary\r\n",
        "def RemoveStopwords(text):\r\n",
        "    words = [w for w in text if w not in stopwords.words('english')]\r\n",
        "    return words \r\n",
        "\r\n",
        "# To combine tokenized words if necessary\r\n",
        "def CombineText(list_of_text):\r\n",
        "    combined_text = ' '.join(list_of_text)\r\n",
        "    return combined_text\r\n",
        "\r\n",
        "def StemWords(text, stemmer):\r\n",
        "  text = \" \".join([stemmer.stem(word) for word in text.split()])\r\n",
        "  return text\r\n",
        "\r\n",
        "def LemmatizeWords(text,lemmatizer):\r\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erFA7A7bY-dd"
      },
      "source": [
        "#Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn4ofZ6y--QP"
      },
      "source": [
        "Pipleline to perfrom all preprocessing functions.\r\n",
        "\r\n",
        "Non - required for preprocessing can be made false\r\n",
        "\r\n",
        "**Default values**\r\n",
        "\r\n",
        "remove_url=True, extract_url=False, remove_punctutation=True, extract_hashtag=False, \r\n",
        "                  lower_text_case=True, remove_nos=True, fix_common_tweet_errors=False,\r\n",
        "                  remove_hashtag=False, remove_stopwords=False, combine_text=False,\r\n",
        "                  extract_mentioned = True, remove_mentioned=False, stem_words=False,\r\n",
        "                  lemmatize_words=False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ_OOIsbo2yg"
      },
      "source": [
        "def CleanTextData(Data, remove_url=True, extract_url=False, remove_punctutation=True, extract_hashtag=False, \r\n",
        "                  lower_text_case=True, remove_nos=True, fix_common_tweet_errors=False,\r\n",
        "                  remove_hashtag=False, remove_stopwords=False, combine_text=False,\r\n",
        "                  extract_mentioned = True, remove_mentioned=False, stem_words=False,\r\n",
        "                  lemmatize_words=False, remove_emoji=True, extract_emoji=False,\r\n",
        "                  extract_emoticons=False, remove_emoticons=True, remove_html_tags=True,\r\n",
        "                  convert_html_text=False, chat_lingo_replace=True, spell_check=False\r\n",
        "                  ):\r\n",
        "  if convert_html_text:\r\n",
        "    from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "  \r\n",
        "  Data = Data.assign(text_pre_pro = lambda x: (x['text'].apply(lambda x:BasicTextProcessing(x, remove_url, lower_text_case,\r\n",
        "                        remove_nos, remove_punctutation, remove_html_tags, convert_html_text,\r\n",
        "                        chat_lingo_replace))))\r\n",
        "\r\n",
        "  if fix_common_tweet_errors:\r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:FixCommonTweetErrors(x, remove_hashtag, remove_mentioned, remove_emoji, remove_emoticons)) \r\n",
        "\r\n",
        "  if extract_hashtag:\r\n",
        "    Data = Data.assign(hashtag=lambda x: (x['text'].apply(lambda x:Extracthashtag(x))))\r\n",
        "\r\n",
        "  if extract_url:\r\n",
        "    Data = Data.assign(url=lambda x: (x['text'].apply(lambda x:ExtractURL(x))))\r\n",
        "\r\n",
        "  if extract_mentioned:\r\n",
        "    Data = Data.assign(mentioned=lambda x: (x['text'].apply(lambda x:ExtractMentioned(x))))\r\n",
        "\r\n",
        "  if extract_emoji:\r\n",
        "    Data = Data.assign(emoji=lambda x: (x['text'].apply(lambda x:ExtractEmoji(x))))\r\n",
        "\r\n",
        "  if extract_emoticons:\r\n",
        "    Data = Data.assign(emoticons=lambda x: (x['text'].apply(lambda x:ExtractEmoticons(x))))\r\n",
        "  \r\n",
        "\r\n",
        "  if remove_punctutation:\r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:RemovePunctutation(x))\r\n",
        "\r\n",
        "  if spell_check:\r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:SpellCheck(x))\r\n",
        " \r\n",
        "  if remove_stopwords:\r\n",
        "    LoadStopwords()\r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:RemoveStopwords(x))\r\n",
        "\r\n",
        "  if combine_text:\r\n",
        "    Data['tokenized_processed'] = Data['text_pre_pro'].apply(lambda x:CombineText(x))\r\n",
        "\r\n",
        "  if stem_words:\r\n",
        "    stemmer = PorterStemmer()\r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:StemWords(x, stemmer))\r\n",
        "\r\n",
        "  if lemmatize_words:    \r\n",
        "    lemmatizer = WordNetLemmatizer()  \r\n",
        "    Data['text_pre_pro'] = Data['text_pre_pro'].apply(lambda x:LemmatizeWords(x, lemmatizer))\r\n",
        "  Data = Data.assign(tokenized_processed=lambda x: (x['text_pre_pro'].apply(lambda x:tokenizer.tokenize(x))))\r\n",
        " \r\n",
        "\r\n",
        "  return Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpNTHisMZCVF"
      },
      "source": [
        "#Processing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57IHXMZ3y-jQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e028611d-8d6b-435d-eb6e-d23b38b5e525"
      },
      "source": [
        "Tweets_PreProcessed = CleanTextData(Tweets, extract_hashtag=True, \r\n",
        "                                        fix_common_tweet_errors=True,\r\n",
        "                                        extract_url = True,\r\n",
        "                                        remove_mentioned=True,\r\n",
        "                                        )\r\n",
        "\r\n",
        "# Some ids of tweets which can be used to check if the prrocssing had the inteded\r\n",
        "# effect on the tweets\r\n",
        "# listofid = [28, 109, 158, 220, 232, 409, 1722]\r\n",
        "\r\n",
        "# for i in listofid:\r\n",
        "#   print(Tweets_PreProcessed.loc[Tweets_PreProcessed['id'] == i, ['text', 'text_pre_pro']])\r\n",
        "\r\n",
        "Tweets_PreProcessed.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_pre_pro</th>\n",
              "      <th>hashtag</th>\n",
              "      <th>url</th>\n",
              "      <th>mentioned</th>\n",
              "      <th>tokenized_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td>1</td>\n",
              "      <td>our deeds are the reason of this earthquake may allah forgive us all</td>\n",
              "      <td>[earthquake]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, earthquake, may, allah, forgive, us, all]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
              "      <td>1</td>\n",
              "      <td>all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[all, residents, asked, to, shelter, in, place, are, being, notified, by, officers, no, other, evacuation, or, shelter, in, place, orders, are, expected]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive wildfires evacuation orders in california</td>\n",
              "      <td>[wildfires]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[people, receive, wildfires, evacuation, orders, in, california]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location  \\\n",
              "0   1     NaN      NaN   \n",
              "1   4     NaN      NaN   \n",
              "2   5     NaN      NaN   \n",
              "3   6     NaN      NaN   \n",
              "\n",
              "                                                                                                                                    text  \\\n",
              "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
              "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
              "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
              "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
              "\n",
              "   target  \\\n",
              "0       1   \n",
              "1       1   \n",
              "2       1   \n",
              "3       1   \n",
              "\n",
              "                                                                                                                         text_pre_pro  \\\n",
              "0                                                                our deeds are the reason of this earthquake may allah forgive us all   \n",
              "1                                                                                               forest fire near la ronge sask canada   \n",
              "2  all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected   \n",
              "3                                                                           people receive wildfires evacuation orders in california    \n",
              "\n",
              "        hashtag  url mentioned  \\\n",
              "0  [earthquake]  NaN       NaN   \n",
              "1           NaN  NaN       NaN   \n",
              "2           NaN  NaN       NaN   \n",
              "3   [wildfires]  NaN       NaN   \n",
              "\n",
              "                                                                                                                                         tokenized_processed  \n",
              "0                                                                         [our, deeds, are, the, reason, of, this, earthquake, may, allah, forgive, us, all]  \n",
              "1                                                                                                              [forest, fire, near, la, ronge, sask, canada]  \n",
              "2  [all, residents, asked, to, shelter, in, place, are, being, notified, by, officers, no, other, evacuation, or, shelter, in, place, orders, are, expected]  \n",
              "3                                                                                           [people, receive, wildfires, evacuation, orders, in, california]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m1SMT_JfSAG"
      },
      "source": [
        "# Tweets_PreProcessed['mentioned'][Tweets_PreProcessed['mentioned'].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5YuH8mCnaZO"
      },
      "source": [
        "Tweets_PreProcessed.to_csv('train_processed.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L87NQXZAVY-"
      },
      "source": [
        "Reset the variables if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcv1o-RaCgDU"
      },
      "source": [
        "# %reset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ypA4zWwcUU"
      },
      "source": [
        "#Sub Program to write new values to dicts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnNPWdFjwrgr",
        "outputId": "47da8cc3-58fe-41d5-cff2-97a3c8c59366"
      },
      "source": [
        "contractions_dict.items()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(\"ain't\", 'are not'), (\"'s\", ' is'), (\"aren't\", 'are not'), (\"can't\", 'cannot'), (\"can't've\", 'cannot have'), (\"'cause\", 'because'), (\"could've\", 'could have'), (\"couldn't\", 'could not'), (\"couldn't've\", 'could not have'), (\"didn't\", 'did not'), (\"doesn't\", 'does not'), (\"don't\", 'do not'), (\"hadn't\", 'had not'), (\"hadn't've\", 'had not have'), (\"hasn't\", 'has not'), (\"haven't\", 'have not'), (\"he'd\", 'he would'), (\"he'd've\", 'he would have'), (\"he'll\", 'he will'), (\"he'll've\", 'he will have'), (\"how'd\", 'how did'), (\"how'd'y\", 'how do you'), (\"how'll\", 'how will'), (\"i'd\", 'i would'), (\"i'd've\", 'i would have'), (\"i'll\", 'i will'), (\"i'll've\", 'i will have'), (\"i'm\", 'i am'), (\"i've\", 'i have'), (\"isn't\", 'is not'), (\"it'd\", 'it would'), (\"it'd've\", 'it would have'), (\"it'll\", 'it will'), (\"it'll've\", 'it will have'), (\"let's\", 'let us'), (\"ma'am\", 'madam'), (\"mayn't\", 'may not'), (\"might've\", 'might have'), (\"mightn't\", 'might not'), (\"mightn't've\", 'might not have'), (\"must've\", 'must have'), (\"mustn't\", 'must not'), (\"mustn't've\", 'must not have'), (\"needn't\", 'need not'), (\"needn't've\", 'need not have'), (\"o'clock\", 'of the clock'), (\"oughtn't\", 'ought not'), (\"oughtn't've\", 'ought not have'), (\"shan't\", 'shall not'), (\"sha'n't\", 'shall not'), (\"shan't've\", 'shall not have'), (\"she'd\", 'she would'), (\"she'd've\", 'she would have'), (\"she'll\", 'she will'), (\"she'll've\", 'she will have'), (\"should've\", 'should have'), (\"shouldn't\", 'should not'), (\"shouldn't've\", 'should not have'), (\"so've\", 'so have'), (\"that'd\", 'that would'), (\"that'd've\", 'that would have'), (\"there'd\", 'there would'), (\"there'd've\", 'there would have'), (\"they'd\", 'they would'), (\"they'd've\", 'they would have'), (\"they'll\", 'they will'), (\"they'll've\", 'they will have'), (\"they're\", 'they are'), (\"they've\", 'they have'), (\"to've\", 'to have'), (\"wasn't\", 'was not'), (\"we'd\", 'we would'), (\"we'd've\", 'we would have'), (\"we'll\", 'we will'), (\"we'll've\", 'we will have'), (\"we're\", 'we are'), (\"we've\", 'we have'), (\"weren't\", 'were not'), (\"what'll\", 'what will'), (\"what'll've\", 'what will have'), (\"what're\", 'what are'), (\"what've\", 'what have'), (\"when've\", 'when have'), (\"where'd\", 'where did'), (\"where've\", 'where have'), (\"who'll\", 'who will'), (\"who'll've\", 'who will have'), (\"who've\", 'who have'), (\"why've\", 'why have'), (\"will've\", 'will have'), (\"won't\", 'will not'), (\"won't've\", 'will not have'), (\"would've\", 'would have'), (\"wouldn't\", 'would not'), (\"wouldn't've\", 'would not have'), (\"y'all\", 'you all'), (\"y'all'd\", 'you all would'), (\"y'all'd've\", 'you all would have'), (\"y'all're\", 'you all are'), (\"y'all've\", 'you all have'), (\"you'd\", 'you would'), (\"you'd've\", 'you would have'), (\"you'll\", 'you will'), (\"you'll've\", 'you will have'), (\"you're\", 'you are'), (\"you've\", 'you have'), ('\\\\bim\\\\b', 'i am')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3TKi8bkAanG"
      },
      "source": [
        "Add any new values to the dicts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsyuGJOFw9c-"
      },
      "source": [
        "contractions_dict['CONTRACTED WORD'] = 'EXPANDED WORD'\r\n",
        "repetitions_dict['REPEATED LETTER WORD'] = 'CONTRACTED WORD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61anLndaAvyW"
      },
      "source": [
        "Save the dict and use it for further preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8k8Az4wcsl"
      },
      "source": [
        "with open('contractions_dict.json', 'w') as fp:\r\n",
        "    json.dump(contractions_dict, fp)\r\n",
        "with open('repetitions_dict.json', 'w') as fp:\r\n",
        "    json.dump(repetitions_dict, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW6_3w1oBAij"
      },
      "source": [
        "#Sub Program to find list of words with repeated leterrs (Eg: gooooaaalll)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yqerKkVAhiI"
      },
      "source": [
        "Check the number of words with repeated letters in your dataset and add any new words to the dict if necessary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQl-0KhK2pet",
        "outputId": "66026a69-ea22-467b-8f75-0cf7e0718263"
      },
      "source": [
        "word_corpus = []\r\n",
        "j = 0\r\n",
        "for tweet in Tweets_PreProcessed['tokenized_processed']:\r\n",
        "  for word in tweet:\r\n",
        "    if word in word_corpus:\r\n",
        "      j = j +1\r\n",
        "    else:\r\n",
        "      word_corpus.append(word)\r\n",
        "print(len(word_corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BECUuqSQ40Us",
        "outputId": "6effa846-0979-4843-fb60-9bcf8e43b908"
      },
      "source": [
        "Consec_2_letter_words = []\r\n",
        "for word in word_corpus:\r\n",
        "  for idx, char in enumerate(word):\r\n",
        "    if idx + 1 < len(word):\r\n",
        "      if word[idx] == word[idx + 1]:\r\n",
        "        Consec_2_letter_words.append(word)\r\n",
        "print(len(Consec_2_letter_words))\r\n",
        "print(Consec_2_letter_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4160\n",
            "['deeds', 'allah', 'all', 'officers', 'school', 'flood', 'flooding', 'streets', 'hill', 'see', 'woods', 'happening', 'across', 'street', 'three', 'getting', 'flooded', 'gonna', 'arrived', 'summer', 'cool', 'skiing', 'week', 'bbcmtd', 'look', 'will', 'office', 'soooo', 'soooo', 'soooo', 'followers', 'better', 'setting', 'alexissanchez', 'happy', 'teammates', 'gunners', 'offices', 'voortrekker', 'voortrekker', 'kiss', 'filled', 'peeps', 'farewell', 'progressive', 'greetingsin', 'fallen', 'hood', 'buff', 'accident', 'impossible', 'nashvilletraffic', 'nashvilletraffic', 'traffic', 'caraccidentlawyer', 'speeding', 'teen', 'accidents', 'tee', 'curry', 'awareness', 'mooresville', 'mooresville', 'iredell', 'sleepjunkies', 'sleeping', 'pills', 'happen', 'cabrillo', 'hwymagellan', 'accidentwho', 'mayonnaise', 'horrible', 'finally', 'pissed', 'donnie', 'tell', 'been', 'ashville', 'crossed', 'naayf', 'chandanee', 'mma', 'rammed', 'eddy', 'willis', 'aashiqui', 'actress', 'aggarwal', 'suffield', 'southaccident', 'langtree', 'financially', 'support', 'happened', 'ill', 'killed', 'still', 'comment', 'issue', 'measuresarrestpastornganga', 'effort', 'bannister', 'icemoon', 'djicemoon', 'shooting', 'guess', 'actually', 'free', 'terrifying', 'roller', 'seeing', 'issues', 'really', 'http', 'bloody', 'silverwood', 'full', 'book', 'esquireattire', 'difficulties', 'osteen', 'between', 'possible', 'tells', 'bb', 'off', 'interrupt', 'shell', 'need', 'error', 'common', 'odds', 'alexalltimelow', 'awwww', 'awwww', 'awwww', 'mhmmm', 'mhmmm', 'cessna', 'official', 'mbataweel', 'naturally', 'little', 'looks', 'terrible', 'statistically', 'worried', 'call', 'begging', 'lorry', 'boss', 'travelling', 'blood', 'skyhawkmm', 'lilreese', 'hella', 'kills', 'thenissonian', 'rejectdcartoons', 'nissan', 'assistance', 'aaceorg', 'passing', 'annihilated', 'nigga', 'shall', 'dessicated', 'kneel', 'baseball', 'meeting', 'celticindeed', 'tneazzy', 'mizzou', 'career', 'careen', 'fella', 'sorry', 'pulls', 'viralspell', 'boom', 'well', 'butthe', 'horror', 'annihilate', 'stopped', 'ball', 'steellord', 'steellord', 'seen', 'officially', 'officially', 'skipping', 'bummer', 'keegan', 'cell', 'summerslam', 'alloosh', 'alloosh', 'food', 'happyhour', 'simmons', 'juanny', 'rvfriedmann', 'hell', 'annihilation', 'annihilating', 'quarterstaff', 'attack', 'theellenshow', 'theellenshow', 'withåêannihilation', 'calfreedommom', 'calfreedommom', 'willienelson', 'less', 'allow', 'whippenz', 'rollingstones', 'current', 'bookslast', 'books', 'following', 'johnny', 'soon', 'feels', 'poor', 'ppor', 'collegeradi', 'feel', 'pullup', 'called', 'fittscott', 'fittscott', 'popularmmos', 'took', 'alexandrapullin', 'indeed', 'grizzly', 'beginning', 'yahootv', 'totally', 'geekapocalypse', 'hesse', 'queen', 'alexshipppp', 'alexshipppp', 'alexshipppp', 'coiffed', 'pbban', 'avysss', 'avysss', 'armageddon', 'kill', 'russaky', 'unless', 'voodoo', 'voodoo', 'rtrrt', 'flawless', 'afflecki', 'occasion', 'hidden', 'door', 'rtrrtcoach', 'aberdeenfc', 'aberdeenfanpage', 'tomorrow', 'coefficient', 'paddytomlinson', 'too', 'brucewillis', 'toddler', 'preppers', 'doomsday', 'collection', 'preppertalk', 'prepper', 'eep', 'messiah', 'dajaal', 'ww', 'impressive', 'till', 'lee', 'ûïleejasper', 'class', 'collapse', 'russia', 'funny', 'gofballs', 'staff', 'aberdeen', 'rally', 'reconnect', 'queens', 'billboard', 'fanarmyfaceoff', 'swiss', 'rubber', 'mtvsummerstar', 'mtvhottest', 'wwi', 'wwii', 'wwii', 'appoints', 'mississippi', 'mississippi', 'mississippi', 'commission', 'commission', 'killings', 'terrorists', 'historicchurch', 'struggling', 'attend', 'add', 'newsintweets', 'stabbing', 'arsonattack', 'kisii', 'huffpostrelig', 'tennessee', 'tennessee', 'tennessee', 'impressed', 'alleged', 'arrested', 'possesion', 'casperrmg', 'bloorossington', 'bloorossington', 'mattress', 'mattress', 'business', 'pcaldicott', 'dupree', 'doofus', 'green', 'elliott', 'elliott', 'terrorism', 'missing', 'pfannebeckers', 'nashville', 'grabbers', 'terror', 'million', 'dattomm', 'dattomm', 'funniest', 'twitter', 'horrific', 'accused', 'allthenews', 'officials', 'terrorist', 'worry', 'volleyball', 'volleyball', 'ii', 'assailant', 'homeless', 'caixxumsos', 'attackshare', 'illegal', 'offenses', 'attacked', 'nickcocofree', 'messeymetoo', 'messeymetoo', 'feeling', 'offended', 'greece', 'geller', 'troll', 'literally', 'loosers', 'kelly', 'aiii', 'aiii', 'needs', 'chill', 'freebitcoin', 'christinalavv', 'lindsaywynn', 'tweets', 'digging', 'kalle', 'mattson', 'reebok', 'cotton', 'xvii', 'rowaa', 'appreciate', 'upper', 'classic', 'sweet', 'weddinghour', 'saddledome', 'inner', 'communication', 'fall', 'fully', 'chiasson', 'rudd', 'filmmakers', 'rigga', 'overall', 'utahgrizz', 'rappers', 'kallemattsons', 'kallemattsons', 'battle', 'bull', 'letter', 'rotten', 'rottentomatoes', 'added', 'assistant', 'kaboom', 'battlemoferadio', 'battledom', 'battlerapchris', 'baaaack', 'baaaack', 'baaaack', 'mildmannered', 'occurred', 'occurred', 'fleets', 'ripped', 'happens', 'cummerbund', 'stormtrooper', 'somme', 'attention', 'mass', 'canberra', 'gallipoli', 'miss', 'fiddle', 'postbattle', 'bioterror', 'jacksonville', 'shipping', 'rickperry', 'commerce', 'subcommittee', 'subcommittee', 'subcommittee', 'htt', 'willing', 'apple', 'alisonannyoung', 'hmmthis', 'orchardalley', 'repression', 'scoopit', 'bioterrorism', 'iii', 'iii', 'carry', 'colluded', 'wbioterrorismanduse', 'darrellissa', 'darrellissa', 'darrellissa', 'keep', 'horrors', 'biosurveillance', 'changebioterrorismmass', 'changebioterrorismmass', 'changebioterrorismmass', 'inequalityyea', 'hollywood', 'hollywood', 'vaccines', 'warrior', 'drrichardbesser', 'drrichardbesser', 'college', 'difficult', 'volunteers', 'needed', 'preparedness', 'drill', 'running', 'pretty', 'hhs', 'stationcdrkelly', 'youngerandgrossly', 'bioterrorismap', 'possibility', 'wugliness', 'bioterrorismim', 'rockefellerchirockefellerunivheiress', 'rockefellerchirockefellerunivheiress', 'rockefellerchirockefellerunivheiress', 'efforts', 'agreements', 'allay', 'pool', 'looking', 'hammond', 'niggas', 'wanna', 'dorrie', 'officialcoredjs', 'bellalinn', 'bellalinn', 'weekend', 'losses', 'weekold', 'battling', 'youll', 'iamrrsb', 'interrogation', 'rapper', 'pizzas', 'jackass', 'stuffin', 'letting', 'babysweet', 'guiltygearxxacp', 'weeks', 'facebook', 'seek', 'djjohnblaze', 'hottest', 'beginnings', 'tweet', 'xdojjjj', 'xdojjjj', 'xdojjjj', 'whopperjr', 'bedrooms', 'acee', 'smooth', 'artisteoftheweekfact', 'agree', 'clubbanger', 'weddings', 'tomorrowaugust', 'dollar', 'skills', 'unfilled', 'roots', 'baseballquotes', 'pattyds', 'gwfrazee', 'joshuaassaraf', 'joshuaassaraf', 'kasadlla', 'bbm', 'roof', 'omgbethersss', 'omgbethersss', 'reddish', 'dummies', 'freezing', 'degree', 'midday', 'bullets', 'officialtjonez', 'blessed', 'missy', 'summertime', 'yeehaw', 'elwoods', 'blazingelwoods', 'proof', 'slapping', 'follow', 'bleeding', 'wellgrounded', 'readiness', 'nugget', 'written', 'allowed', 'apparently', 'rubbing', 'darrylb', 'foot', 'stepped', 'glass', 'feet', 'dinner', 'jannet', 'fell', 'deadpool', 'wannabe', 'burberryant', 'soccer', 'tammyw', 'elijahmallari', 'coloiccarnality', 'wedding', 'damnaarielle', 'damnaarielle', 'oomf', 'follower', 'jazz', 'misstep', 'upliterally', 'keeping', 'pulled', 'robsimss', 'cantmisskid', 'iphooey', 'ironically', 'bachmann', 'retweeted', 'yahooschwab', 'recommend', 'shoppe', 'horrorsharperanetflixshow', 'fireball', 'falling', 'adrianpeel', 'blightthat', 'realhotcullen', 'deep', 'toddcalfee', 'toddcalfee', 'mattburgener', 'whitt', 'snuff', 'beer', 'greenspace', 'constellation', 'excellence', 'matters', 'apperception', 'xxhjesc', 'healthweekly', 'willhillbet', 'willhillbet', 'app', 'zippoline', 'community', 'greening', 'anellatulip', 'refugee', 'detroitthe', 'blizzard', 'blizzarddraco', 'blizzarddraco', 'stevenontwatter', 'pussyxdestroyer', 'radioriffrocks', 'msmiggi', 'tweettaiji', 'tweettaiji', 'blizzardfans', 'rolling', 'blizzardgamin', 'butter', 'cookie', 'controllers', 'tomorrows', 'disappointed', 'lonewolffur', 'fairxx', 'blizzardcs', 'bubblycuteone', 'batter', 'biggest', 'butterfinger', 'cook', 'wall', 'floor', 'associated', 'bookanother', 'tatoo', 'pressure', 'cuffs', 'chamberedblood', 'stressful', 'excellent', 'porridge', 'scotto', 'shii', 'filling', 'gotta', 'sbee', 'roll', 'ellie', 'acesse', 'nosso', 'polluted', 'aggressif', 'aggressif', 'aggressive', 'aggressive', 'butterlondon', 'bbloggers', 'bbloggers', 'sally', 'forrest', 'xxx', 'xxx', 'looked', 'grrrr', 'grrrr', 'grrrr', 'weekends', 'summers', 'drools', 'effects', 'diarrhea', 'girlfrienddown', 'itsmegss', 'hello', 'mariasherwood', 'johnjcampbell', 'marvellous', 'beet', 'wwwbigbaldhead', 'wwwbigbaldhead', 'jessienojoke', 'melissaross', 'melissaross', 'meet', 'supposed', 'zzzz', 'zzzz', 'zzzz', 'sitting', 'remorseless', 'killer', 'bloodymonday', 'williams', 'steel', 'shuffle', 'shopping', 'bedroom', 'walls', 'papcrdoll', 'pilloried', 'inning', 'spammers', 'supposedly', 'lmfaoooo', 'lmfaoooo', 'lmfaoooo', 'machinegunkelly', 'creeper', 'approval', 'todd', 'ee', 'buddy', 'patterns', 'twosall', 'sufficiently', 'utterly', 'vanessas', 'guaranteed', 'bitten', 'butt', 'fullblown', 'givebackkalinwhiteaccount', 'givebackkalinwhiteaccount', 'princessduck', 'orbette', 'kennel', 'ass', 'metaphorically', 'bottle', 'cross', 'ditto', 'mulberry', 'messenger', 'buffalo', 'vuitton', 'cultsierre', 'copper', 'zipped', 'pochette', 'nuu', 'rhee', 'mattbez', 'bagging', 'meek', 'killing', 'meekmill', 'meekmill', 'trollingtilmeekdiss', 'trollingtilmeekdiss', 'trollingtilmeekdiss', 'philly', 'yankees', 'skimmed', 'missed', 'lyrically', 'cuffed', 'bodybagging', 'wwe', 'mycareer', 'diss', 'mill', 'hushhes', 'officialrealrap', 'bagged', 'beef', 'ûïmacdaddyleo', 'jengriffinfnc', 'arrival', 'bestseller', 'cartoon', 'fossil', 'boomerangtime', 'sopameer', 'wattashit', 'appears', 'arriving', 'hall', 'charlotte', 'redbull', 'putting', 'football', 'football', 'coffins', 'rooms', 'tommorow', 'messengers', 'small', 'zippers', 'deeeznvtzzz', 'deeeznvtzzz', 'deeeznvtzzz', 'deeeznvtzzz', 'russian', 'calls', 'scottwalker', 'middle', 'bagscutekitten', 'summerinsweden', 'katt', 'katterpì', 'lattice', 'studded', 'bigger', 'congress', 'sweeping', 'shoot', 'pattern', 'crossbody', 'ella', 'zipper', 'coffee', 'coffee', 'quadrillion', 'comments', 'dropped', 'namjoons', 'collab', 'aaronthefm', 'cranboonitz', 'ûïdylanmcclure', 'smallforestelf', 'umm', 'carrying', 'ahh', 'swellyjetevo', 'anniversary', 'appropriate', 'pepper', 'oopsh', 'coastfell', 'themalemadonna', 'playoffs', 'bell', 'sweetiebirks', 'mirrorlady', 'screenshot', 'elephantintheroom', 'dramatically', 'plummeted', 'village', 'nicklee', 'bathroom', 'loo', 'oooureli', 'oooureli', 'abubaraa', 'hannabrooksie', 'hannabrooksie', 'preemptive', 'cheetosarabia', 'cheetos', 'hopefully', 'compassion', 'bannukes', 'according', 'vagersedolla', 'villages', 'pkk', 'johnejefferson', 'fleeing', 'bellybombed', 'pass', 'hurricane', 'mission', 'settingsuccess', 'settingsuccess', 'settingsuccess', 'bells', 'toll', 'smallbusiness', 'smallbusiness', 'neoprogressive', 'rtsanddemocracy', 'narrative', 'bill', 'tolled', 'marshall', 'ameenshaikh', 'hyatt', 'huffpostarts', 'caribbean', 'jewishpress', 'mpp', 'johannesburg', 'bloopandablast', 'tuffers', 'aussie', 'batting', 'bbctms', 'stuff', 'followlasg', 'urgentthere', 'currently', 'killsåêone', 'aan', 'sureshpprabhu', 'illuminated', 'mmm', 'mmm', 'businesses', 'minimehh', 'overlooking', 'blacklivesmatter', 'fewmoretweets', 'matter', 'outta', 'mentally', 'messi', 'tatoos', 'bloodronaldo', 'looting', 'kellys', 'schools', 'strikesstrikes', 'allegiance', 'doctorfluxx', 'spinnellii', 'spinnellii', 'spinnellii', 'embarrassing', 'embarrassing', 'weep', 'leeds', 'zourryart', 'rockbottomradfm', 'challenges', 'tonne', 'gbbo', 'ppfa', 'witness', 'struggle', 'iaff', 'reeves', 'installation', 'cladding', 'greenbuildermag', 'ross', 'booty', 'different', 'tweetlikeitsseptemberth', 'tweetlikeitsseptemberth', 'shootings', 'baffles', 'grills', 'ppsellsbabyparts', 'ppsellsbabyparts', 'bbcintroducing', 'mafireems', 'jennasjems', 'charred', 'threealarm', 'rebelled', 'swooping', 'progress', 'robbie', 'moon', 'cheese', 'runkeeper', 'photoop', 'myfitnesspal', 'pepperoni', 'coolest', 'kennethbauer', 'grilled', 'wood', 'innings', 'thomasvissman', 'keithyyl', 'keithyy', 'gettin', 'degrees', 'fool', 'allpro', 'nuggets', 'cutting', 'yall', 'letsfootball', 'letsfootball', 'skanndtyagi', 'totteham', 'markkriegsman', 'weightless', 'skinny', 'bulletproof', 'bulletproof', 'mullin', 'sjubb', 'johnsontionne', 'huffpostcomedy', 'keeps', 'attendees', 'attendees', 'steep', 'terrain', 'sniff', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'donny', 'uhhhhh', 'uhhhhh', 'uhhhhh', 'uhhhhh', 'apply', 'balls', 'jerry', 'press', 'minsuwoongs', 'accidentally', 'accidentally', 'planned', 'parenthood', 'pp', 'strutting', 'aiiamericangiri', 'looters', 'dhsscitech', 'duckvillelol', 'ppl', 'attempting', 'retweet', 'pulling', 'booradleyvancullen', 'booradleyvancullen', 'puppies', 'attacking', 'kitten', 'kshllcenterpri', 'progressohio', 'understood', 'express', 'streetlight', 'mitt', 'seems', 'moonbeam', 'appreciativeinquiry', 'hillary', 'standwithpp', 'dacherryontop', 'swimming', 'peeters', 'affected', 'eggs', 'calling', 'ieee', 'ieee', 'attackclose', 'sees', 'bottling', 'eventually', 'countless', 'lasvegaslocally', 'account', 'fallingoffstool', 'fallingoffstool', 'fallingoffstool', 'sorrow', 'shooter', 'followup', 'allied', 'countermoonbat', 'voodooben', 'voodooben', 'passed', 'thankfully', 'command', 'francisunderwood', 'ftsnnewsdesk', 'allies', 'commercial', 'critically', 'gritty', 'amicospizzato', 'seeyouatamicos', 'recall', 'disconnected', 'scriptettesar', 'katiecool', 'telling', 'correlate', 'greenharvard', 'agrees', 'conning', 'reriellechan', 'willinghearted', 'unsuccessful', 'unsuccessful', 'millions', 'messy', 'agreed', 'appleofficlal', 'appleofficlal', 'suffering', 'tcotåêccot', 'borrowers', 'puppet', 'fulfilling', 'gemmahentsch', 'megynkelly', 'committed', 'committed', 'bless', 'maatmhi', 'diff', 'barry', 'generally', 'lorries', 'vanilla', 'controlled', 'reckless', 'bottom', 'coffees', 'coffees', 'tweetstorm', 'bbc', 'discussion', 'sheer', 'herring', 'success', 'success', 'follows', 'catastrophicfallenangel', 'reveillertm', 'marginoferror', 'theyll', 'jamesmelville', 'kessler', 'satellites', 'assume', 'disagreements', 'occurrence', 'occurrence', 'illinois', 'weeklong', 'upsetting', 'bee', 'savebees', 'collapsed', 'cnnbrk', 'bees', 'spillevacuationsred', 'seattle', 'spill', 'loot', 'planning', 'suppose', 'obsessed', 'deezercolombia', 'glitter', 'pill', 'cliff', 'dannyjohnjules', 'dmunni', 'jeannamibian', 'proceeds', 'crossfit', 'billers', 'billings', 'cliffhumble', 'leezy', 'grabbing', 'regress', 'funnynews', 'collapses', 'groom', 'adding', 'sleep', 'sincerelyevelnn', 'szmnextdoor', 'ferry', 'allin', 'cliffs', 'kidding', 'cilla', 'collapseblow', 'halloikbenwill', 'halloikbenwill', 'geoffrickly', 'yahoo', 'trapped', 'dccomics', 'greeces', 'ââ', 'commodity', 'dogg', 'correction', 'warsgoddess', 'warsgoddess', 'knees', 'ferrochrome', 'billiton', 'ûïthehighfessions', 'mtgrotto', 'wmiddle', 'bbakeb', 'offs', 'dorrets', 'organicallyrude', 'mattingly', 'alley', 'sobbing', 'endlessly', 'oneheartonemindonecss', 'puddle', 'durrellb', 'durrellb', 'heartless', 'whipped', 'officer', 'rokiieee', 'rokiieee', 'rokiieee', 'heels', 'greek', 'fools', 'wallybaiter', 'flickershowell', 'sqwizzix', 'collide', 'ripple', 'lesleychappelle', 'lesleychappelle', 'cigarette', 'immediately', 'jogger', 'gucci', 'masses', 'untill', 'fill', 'nlccollide', 'nlccollide', 'gassymexican', 'mattcohenfake', 'gamma', 'tackettdc', 'suddenly', 'gemma', 'collideworship', 'thedoolinggroup', 'thedoolinggroup', 'spells', 'wattys', 'wattpad', 'teenfiction', 'collided', 'runner', 'greenway', 'jessicastclair', 'gilmoreguysshow', 'ihaveepisodesofgg', 'ihaveepisodesofgg', 'suffered', 'iilanjut', 'assault', 'uselessthe', 'skull', 'huzzah', 'mollythetanzs', 'glassanimals', 'monsoon', 'chippewa', 'wheeler', 'anna', 'alaskaseafood', 'beep', 'ssp', 'airbullet', 'happily', 'commence', 'pple', 'room', 'harrystyles', 'oharrybecareful', 'collision', 'opp', 'collisiono', 'tunnel', 'shopcollision', 'creek', 'flynn', 'knott', 'valley', 'collisionunkn', 'missjadebrown', 'occupants', 'volunteer', 'meetinghopefully', 'meetinghopefully', 'lougheed', 'skaggs', 'offramp', 'approaching', 'kierannicholson', 'rhett', 'worries', 'beginners', 'slamming', 'lesson', 'molloy', 'mm', 'tullamarine', 'apparent', 'salyersblairhall', 'jennas', 'feelin', 'tools', 'tool', 'barrington', 'hills', 'hoffman', 'floors', 'scheer', 'muzzamil', 'offr', 'neileastwood', 'brianroemmele', 'shaheed', 'rosewell', 'heywood', 'olliebailey', 'intactmhpartliftsoddsplaneglidednotcrashedintosea', 'yahoofinancehope', 'loss', 'hicksville', 'overtook', 'ttw', 'kuualohax', 'mommyisbomb', 'jorrynja', 'terell', 'explicitpretty', 'loveyouuuu', 'loveyouuuu', 'loveyouuuu', 'overrated', 'crushmtvhottest', 'mrrobinson', 'tweeted', 'tiffanyfrizzell', 'tiffanyfrizzell', 'tiffanyfrizzell', 'sooo', 'sooo', 'kenny', 'holland', 'disappoints', 'jimmyfallon', 'jimmyfallon', 'squirrel', 'worstsummerjob', 'stress', 'exceptionally', 'pressed', 'flurry', 'clelliyou', 'brasswork', 'ccmusic', 'commenters', 'disillusioned', 'checkhappy', 'musiccheckall', 'musiccheckall', 'pperez', 'attacks', 'michelleellle', 'michelleellle', 'michelleellle', 'michelleellle', 'teenagers', 'bobbyxfisher', 'exofficio', 'emaaalay', 'emaaalay', 'aptlyengineerd', 'emmychappy', 'emmychappy', 'reddakushgodd', 'reddakushgodd', 'hassle', 'freefrom', 'stupidniggr', 'appointment', 'freedom', 'rubbery', 'annual', 'hoops', 'ppdr', 'mccauleysdesign', 'wordpressdotcom', 'softball', 'bulletin', 'typhoon', 'ûïhannaph', 'warningissued', 'valle', 'hanna', 'issued', 'address', 'address', 'passion', 'unstoppable', 'bhaijaan', 'speed', 'kyee', 'cherry', 'ootd', 'supportive', 'economically', 'collateral', 'lncolyellowstone', 'fitness', 'knee', 'difficulty', 'drumming', 'spotting', 'baggage', 'dragneel', 'shitton', 'tree', 'falls', 'beelievedc', 'offer', 'prolly', 'trillion', 'crosses', 'metallica', 'crosssectarian', 'crosssectarian', 'wonderousallure', 'hhello', 'hhello', 'pussy', 'boobs', 'statesville', 'leedstraif', 'occurs', 'jsunnews', 'richarkkirkarch', 'queenswharf', 'controlpseudojuuzo', 'gettinglost', 'jennellensbb', 'jennellensbb', 'jennellensbb', 'blizzheroes', 'dyannbridges', 'trespass', 'therealrittz', 'fettilootch', 'fettilootch', 'slanglucci', 'oppressions', 'oppressions', 'especially', 'riverroaming', 'bluebirddenver', 'turnedonfetaboo', 'gunnersfan', 'mueller', 'snotgreen', 'cjbanning', 'argsuppose', 'attained', 'rightsgenerally', 'naaa', 'naaa', 'emmerdale', 'attractive', 'soapscoop', 'iwasdisappointedby', 'telltales', 'kgvaal', 'lmaovv', 'kwaaaaadead', 'kwaaaaadead', 'kwaaaaadead', 'kwaaaaadead', 'mikeparractor', 'showwent', 'moores', 'wyrmwood', 'summerfate', 'bff', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'gainesville', 'papiichampoo', 'papiichampoo', 'supports', 'rss', 'shitty', 'seemeth', 'kellkane', 'narrowly', 'screamqueens', 'allahsfinest', 'smoochy', 'bicentennial', 'mullah', 'deathholy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'shoook', 'shoook', 'snippets', 'legionnaires', 'vaxshill', 'looses', 'fidayeen', 'superfood', 'stalled', 'runners', 'foodborne', 'illness', 'illness', 'frackfreelancs', 'deccgovuk', 'frackfreeeu', 'frackfreeeu', 'adiossuperbacterias', 'usually', 'eazzyp', 'seemed', 'warranted', 'applies', 'blackpool', 'specifically', 'chrissie', 'finn', 'tobiasellwood', 'tobiasellwood', 'critters', 'disappeared', 'disappearance', 'billneelynbc', 'billneelynbc', 'seem', 'dustpiggies', 'feed', 'yyeso', 'unfollow', 'floods', 'whatsapp', 'bloodyminded', 'forrestmankins', 'normally', 'odd', 'torrent', 'recommended', 'amsosorry', 'programme', 'dressing', 'incessant', 'applied', 'chuckswindoll', 'differently', 'mishacollins', 'fiendnikki', 'houghjeff', 'dougkessler', 'bbagency', 'billionaire', 'assnchat', 'blessing', 'mallord', 'william', 'darkness', 'clicca', 'susinesses', 'rainfall', 'poorly', 'teens', 'lisatoddsutton', 'lisatoddsutton', 'squabble', 'immigration', 'eurotunnel', 'itsllikely', 'accionempresa', 'feelings', 'doone', 'permission', 'tallest', 'arianareed', 'badotweet', 'barthubbuch', 'weei', 'demolishdeep', 'etoffe', 'clothesless', 'abbswinston', 'exassembly', 'emmanuel', 'root', 'manhood', 'sell', 'jollyjinu', 'businessman', 'orianna', 'rihanna', 'gummy', 'dribbling', 'embarrassment', 'embarrassment', 'engineers', 'embarrassed', 'embarrassed', 'stiiilo', 'stiiilo', 'papicongress', 'saddlebrooke', 'saddlebrooke', 'meerkat', 'snowball', 'ûïsplottdave', 'bbsnews', 'kidnapped', 'stallion', 'jackmulholland', 'freestyles', 'witnessed', 'messnermatthew', 'messnermatthew', 'abbruchsimulator', 'czallstarwes', 'grill', 'ffa', 'foodstand', 'appreciated', 'ahhhhh', 'ahhhhh', 'ahhhhh', 'ahhhhh', 'soonersportstv', 'willow', 'battles', 'canberras', 'fluffy', 'tookem', 'jobbing', 'shantaeskyy', 'blessings', 'modelbubbles', 'emiiliexirwin', 'agreeshe', 'bloomberg', 'freesikhpoliticalprisnors', 'temecafreeman', 'alllivesmatter', 'alllivesmatter', 'alllivesmatter', 'necessary', 'thejenmorillo', 'dallas', 'mood', 'colleenmnelson', 'colleenmnelson', 'hooligans', 'crooks', 'mzmandilynn', 'donzilla', 'meddling', 'yahoonews', 'assembly', 'worthless', 'passengers', 'commute', 'nopassenger', 'illustration', 'freeing', 'wtwitter', 'passenger', 'crippling', 'adamtuss', 'wheel', 'bobbyofhomewood', 'bobbyofhomewood', 'dropping', 'mess', 'chipper', 'cools', 'offers', 'deepthoughts', 'itsqueenbaby', 'cnn', 'gerryconolly', 'gerryconolly', 'nonpassenger', 'ohyayyyyay', 'ohyayyyyay', 'ohyayyyyay', 'teamfollowback', 'followback', 'chicagoscanner', 'knoxville', 'villagers', 'fdstill', 'applaud', 'indiannews', 'alvinnelson', 'collisions', 'immediate', 'ttes', 'cottage', 'deepest', 'officeofrg', 'tottenham', 'sputtering', 'attitude', 'swells', 'corleonedaboss', 'neighborhood', 'mallelis', 'gotten', 'binellithresa', 'brutally', 'abuseddesolateandlost', 'redeemeth', 'fotofill', 'booksbyroger', 'billroose', 'billroose', 'justdepressing', 'hundredodd', 'unimpressed', 'matt', 'copperfields', 'comingsoon', 'littlebitofbass', 'littlebitofbass', 'sheeran', 'hobbit', 'loose', 'mirkwood', 'scattered', 'freediscountbks', 'thriller', 'jamessnyder', 'ayyy', 'ayyy', 'letters', 'sudden', 'effect', 'loop', 'agalloch', 'thehobbit', 'masse', 'wii', 'asleep', 'grubbing', 'amiibos', 'reggaeboyz', 'cameronciletti', 'copped', 'silly', 'competitiveness', 'commonwealth', 'ppc', 'weaknesses', 'streetjamzdotnet', 'childhood', 'compelling', 'preschool', 'sapphirescallop', 'sapphirescallop', 'oppa', 'oops', 'dazzle', 'engineermatarai', 'mataas', 'elgeotaofeeq', 'emotionally', 'reddevillife', 'reddevillife', 'illusions', 'careers', 'freemurphy', 'hitchhiking', 'ryanoss', 'hitters', 'ûóbbc', 'davidvitter', 'hotteennsfwpornmilf', 'hotteennsfwpornmilf', 'hotteennsfwpornmilf', 'chopped', 'cabbage', 'greed', 'windowgatribble', 'forsee', 'badkitty', 'banned', 'undergroundbestsellers', 'decree', 'russiaukraine', 'standmatthew', 'planners', 'hassanrouhani', 'doomed', 'blossominglilac', 'arrogant', 'appetite', 'bonnegreer', 'bonnegreer', 'propelled', 'illegally', 'illegally', 'tenn', 'tennessean', 'tennessean', 'apollo', 'spinningbot', 'bldrcosheriff', 'rapping', 'channelstvthats', 'hhbu', 'mello', 'apollobrown', 'mwnhappy', 'message', 'nottingham', 'bbctalkback', 'succeed', 'succeed', 'apollobrowns', 'connectorconnecto', 'connectorconnecto', 'connector', 'esteemed', 'll', 'assets', 'waterproof', 'rrusa', 'appys', 'mountaineering', 'waterresistant', 'meganbee', 'kadiegrr', 'pll', 'currensy', 'perrie', 'unnewsteam', 'typhoondevastated', 'ivanberroa', 'rossbarton', 'gobsmackeddevastated', 'buffet', 'indoors', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'allegations', 'aussies', 'utter', 'struggles', 'cnnthe', 'cllrraymogford', 'cllrraymogford', 'ssssnell', 'ssssnell', 'ssssnell', 'ssssnell', 'www', 'www', 'livelihoods', 'perrybellegarde', 'perrybellegarde', 'yyj', 'settlement', 'illustrations', 'momneedscoffee', 'momneedscoffee', 'momneedscoffee', 'sanelesstheory', 'mediterranean', 'massgrave', 'restlessness', 'restlessness', 'philippines', 'livelihood', 'disasterrecovery', 'attempt', 'theneeds', 'jeff', 'slipped', 'hollyorange', 'peoplecommunication', 'gurmeetramrahim', 'appx', 'vannuyscouncil', 'youssefyamani', 'sittwe', 'ihhen', 'refugees', 'galleria', 'internally', 'aggression', 'aggression', 'accuses', 'displacedinjuredkilled', 'opportunity', 'pennlive', 'killeddisplaced', 'killeddisplaced', 'carried', 'arrest', 'billboards', 'refugeesmatter', 'refugeesmatter', 'cityofhummus', 'affect', 'llf', 'relentless', 'jeffpalmer', 'surrounding', 'weed', 'affects', 'pizza', 'meets', 'warnerrobins', 'milledgeville', 'milledgeville', 'gaabyx', 'eerie', 'lakeisabella', 'chillin', 'lwilliams', 'mfsloose', 'buffs', 'reprocussions', 'potentially', 'sorrows', 'kessily', 'allthekidneybeansandsorbetmisha', 'cheer', 'drool', 'kiddie', 'ploppy', 'yellowsread', 'peterduttonmp', 'happenedashley', 'suffice', 'kisses', 'seeker', 'dollars', 'summerk', 'eeasterling', 'fondness', 'janiethekillr', 'sketchbook', 'trees', 'swollen', 'iiii', 'iiii', 'iiii', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'jeesss', 'jeesss', 'jeesss', 'heyimbeeyt', 'welli', 'nigeltanner', 'challenge', 'expressioncheeks', 'expressioncheeks', 'clapping', 'breakingfalling', 'nwspocatello', 'amman', 'disappear', 'morocco', 'totoo', 'lubbock', 'yelling', 'sneezing', 'godness', 'fee', 'screenshots', 'challenging', 'rolls', 'sagacioussaber', 'paratroopers', 'barrier', 'goggles', 'ferries', 'shelli', 'ssw', 'raffirc', 'wells', 'scseestapreparando', 'ageekyfangirl', 'hawaii', 'unnecessary', 'unnecessary', 'rossum', 'difficultpeople', 'nnw', 'nne', 'emmy', 'adanne', 'aa', 'batteries', 'niall', 'mmchale', 'erally', 'milioooo', 'milioooo', 'milioooo', 'weallheartonedirection', 'asshole', 'connection', 'eltorroloco', 'cooking', 'pakistannews', 'pakpattan', 'correspondent', 'oocvg', 'redblood', 'rowysolouisville', 'steveycheese', 'bbcnews', 'mwlippert', 'appalling', 'appalling', 'businessmen', 'queer', 'lessonforlife', 'pressing', 'penneys', 'cree', 'boone', 'tooth', 'teeth', 'grille', 'speedtech', 'seeds', 'lafayette', 'sheltersupport', 'tookitlikeaman', 'runnerjoy', 'careemergencies', 'appeals', 'wasilla', 'akgovbillwalker', 'buffer', 'outbreed', 'addict', 'starr', 'mineenjoyfire', 'messages', 'supply', 'install', 'troops', 'reddit', 'ruthann', 'mccormick', 'yyc', 'roomsgrrrr', 'roomsgrrrr', 'roomsgrrrr', 'roomsgrrrr', 'forreal', 'rebeccaforreal', 'rebeccaforreal', 'accepts', 'specialneeds', 'cbccalgary', 'underpasses', 'approach', 'chillimik', 'brilliant', 'glenstannard', 'essexweather', 'torrance', 'committee', 'committee', 'committee', 'personnel', 'iiemergency', 'access', 'access', 'followme', 'brooklyn', 'missionhills', 'missionhills', 'stressed', 'indifference', 'cabramatta', 'prophetmuhammad', 'trafficalert', 'freeway', 'crosslondon', 'accepte', 'wrapped', 'practically', 'raheelsharif', 'equally', 'nothingness', 'sunnymeade', 'boycottbears', 'summit', 'baffling', 'badass', 'carneross', 'yeaahh', 'yeaahh', 'phillipten', 'cee', 'petty', 'lolapalooza', 'doors', 'fireiii', 'fireiii', 'carriage', 'tennews', 'dancefloor', 'alllll', 'alllll', 'alllll', 'alllll', 'nittys', 'stockwell', 'aimlessly', 'joonma', 'ahhtheenikki', 'ahhtheenikki', 'ahhtheenikki', 'meetkakarotto', 'meetkakarotto', 'offline', 'emilee', 'murfreesboro', 'roosevelt', 'koinnews', 'mall', 'trafford', 'missleylaha', 'hook', 'sunnis', 'outkill', 'travellers', 'faan', 'sheriffs', 'lassics', 'annaciclismo', 'roofing', 'dissertation', 'roofers', 'jaclynsonne', 'oliviaann', 'oliviaann', 'guessing', 'yellow', 'accidently', 'addresses', 'addresses', 'ibrahimmisau', 'seehey', 'feelingmanly', 'misses', 'annealiz', 'oo', 'attjcdemos', 'spinning', 'hitting', 'kendall', 'jenner', 'exploderinshizunemishaemikenjiyuukonomiyahisao', 'matthews', 'cervelli', 'puff', 'allenenbot', 'tagged', 'attackonstiles', 'millionsapunkhang', 'doll', 'facelittle', 'puppy', 'dress', 'imkeepingmydayjob', 'screen', 'thebeginning', 'squeeze', 'lunasagalle', 'artillery', 'fallontonight', 'explosionproof', 'blackberry', 'recalls', 'attendance', 'gmmbc', 'missouri', 'ville', 'bluff', 'colinhoffman', 'blossom', 'correct', 'battery', 'alldaycumshots', 'cumtownbjnuttcumslutgirlslovecum', 'saddle', 'accountable', 'brass', 'freestyle', 'button', 'hpssjd', 'greetingcards', 'discussed', 'moore', 'pittsburgh', 'eyewitness', 'penn', 'squibby', 'accounts', 'kaputt', 'wickett', 'ûïlittle', 'schoolboys', 'illustrated', 'horrifying', 'shedding', 'married', 'freed', 'gallup', 'poll', 'suffer', 'redeem', 'feeding', 'bluebell', 'writescoffee', 'writescoffee', 'rrbc', 'smell', 'rotting', 'smelled', 'mineness', 'lifelettercafe', 'squeezed', 'blubber', 'godells', 'appeared', 'attraction', 'asianshawtyy', 'winnipeg', 'witnesses', 'pee', 'dubbo', 'immigrant', 'arrests', 'spookyfob', 'feelslikefob', 'kindness', 'notto', 'overlooked', 'ballews', 'possess', 'possess', 'expressandstar', 'seattles', 'illnesses', 'illnesses', 'coolweird', 'itll', 'skinless', 'periodggindependencmessage', 'periodggindependencmessage', 'gross', 'dwilliams', 'allocating', 'lobbied', 'immensely', 'downfall', 'freemarketeer', 'freemarketeer', 'lpunbiggiewrap', 'questionfatalityflawless', 'cuddling', 'vgbootcamp', 'zss', 'irrespective', 'careerism', 'jittering', 'tellyfckngo', 'jaycootchi', 'bardissimo', 'tonyakappes', 'babybackreeve', 'grass', 'fatalityuudlk', 'mileena', 'ssb', 'loretta', 'fuddy', 'wondertcc', 'endless', 'cheekiness', 'cheekiness', 'bleeds', 'keeper', 'runnin', 'disappointing', 'passive', 'aggressively', 'aggressively', 'commitment', 'ûahhh', 'ûahhh', 'perrychat', 'opposite', 'cowgirllawyer', 'vegassolitude', 'choosegod', 'scottdpierce', 'billharristv', 'billharristv', 'harrisgle', 'beezersun', 'besttalkradio', 'mcnabbychic', 'foolish', 'poorfran', 'reed', 'selfseeking', 'kissed', 'cypress', 'misshomasttopa', 'misshomasttopa', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'harry', 'canontatoo', 'seanhannity', 'lovefood', 'smelling', 'drummond', 'brooktekle', 'pull', 'wompppp', 'wompppp', 'wompppp', 'eeenice', 'eeenice', 'justinejayyy', 'justinejayyy', 'mineenjoybabes', 'libby', 'bedding', 'philippi', 'choose', 'mnpdnashville', 'nashvillefd', 'smartteks', 'gillibrand', 'factsheet', 'iafflocal', 'bridgeportspeed', 'antiochhickoryhollowtn', 'antiochhickoryhollowtn', 'fees', 'infoorder', 'pictwittercompnpizody', 'summon', 'portgassdk', 'mindless', 'awickedassassin', 'awickedassassin', 'hugged', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'edvinnn', 'edvinnn', 'imtariik', 'witnessing', 'ell', 'thh', 'cwhoops', 'mississauga', 'mississauga', 'flattened', 'cartoonylikewhoa', 'pennies', 'rabbit', 'floored', 'shuffled', 'thee', 'disappearing', 'jimmozel', 'puckflattened', 'grummz', 'bluetooth', 'muppet', 'tweetinglew', 'tersestuff', 'fallacy', 'earrings', 'linerless', 'footballs', 'footballs', 'satanaofhell', 'fizzy', 'offroad', 'floodyou', 'rwrabbit', 'atlarnxx', 'alloy', 'hellotybeeren', 'hellotybeeren', 'vv', 'outdoor', 'intertissue', 'seawalls', 'floodjust', 'peeked', 'immunedeafening', 'bellsmy', 'arrives', 'sittway', 'warlordqueen', 'showersstorms', 'adorableappple', 'adorableappple', 'mmda', 'ukfloods', 'trekkers', 'proudgreenhome', 'seekers', 'wunscreened', 'dcclothesline', 'valleywx', 'ûïbbcengland', 'crabbycale', 'assisting', 'sheriff', 'thankkk', 'thankkk', 'soo', 'sonoranrattler', 'farrakhan', 'madonnamking', 'stunned', 'priceless', 'banerjee', 'approaches', 'abcchicago', 'speccy', 'portaloos', 'serversservers', 'careless', 'floorburnt', 'sweetyoung', 'inbetween', 'nuff', 'tthe', 'reassigned', 'bloom', 'seeweed', 'seeweed', 'knowlddge', 'pharrell', 'pharrell', 'abbyairshow', 'recommendations', 'poss', 'massive', 'wxii', 'kelloggs', 'kelloggs', 'queenåê', 'glasses', 'affecting', 'hailyycstorm', 'golfball', 'sunny', 'pennington', 'darkndtatted', 'doppler', 'yycfringe', 'killhard', 'summons', 'yycstorm', 'pummel', 'errrr', 'errrr', 'errrr', 'hellonwheelsamc', 'hellonwheelsamc', 'talkinghell', 'yycweather', 'captureyyc', 'councilscc', 'commuters', 'harrybecareful', 'leedsrouge', 'audaciousspunk', 'dumbass', 'mmk', 'tagging', 'dinallyhot', 'liferebooting', 'parentsacrossam', 'cc', 'billgates', 'laurenmiller', 'illegals', 'controller', 'reblogged', 'wowsavannah', 'collectibles', 'wwexdreamer', 'malistkiss', 'continually', 'newsbuffalo', 'tastemycupcakee', 'lmfaooo', 'lmfaooo', 'triggered', 'annddd', 'annddd', 'annddd', 'plannedparenthood', 'plannedparenthood', 'fooled', 'classycolkett', 'classycolkett', 'deemed', 'chaboyyhd', 'battlefield', 'phiddleface', 'childress', 'uphill', 'hazarddi', 'daviss', 'vallerand', 'flopping', 'dannyraynard', 'personally', 'bellerin', 'dismissed', 'occupational', 'keen', 'deaddreamer', 'recalled', 'hazardwillian', 'hazarddangerous', 'willian', 'basically', 'wholesaleent', 'offloading', 'hillymountain', 'outlook', 'assessment', 'assessment', 'foodscare', 'offersgo', 'magginodle', 'quarrels', 'hearitfrompatty', 'needle', 'dannyoneil', 'toxiccancerdiseasehazardous', 'tweeting', 'rushhour', 'terwilliger', 'rawfoodbliss', 'rawfoodbliss', 'heebsterrr', 'heebsterrr', 'heebsterrr', 'waseembadami', 'hollywarnexx', 'hollywarnexx', 'klarajoelsson', 'pizzarev', 'wfaaweather', 'cooler', 'amdollela', 'kulli', 'aal', 'thoughwill', 'chilli', 'internallydisplaced', 'presstv', 'hotter', 'greatbritishbakeoff', 'deejayempiresound', 'hellfire', 'surrounded', 'deedeecasey', 'deedeecasey', 'bookofdaniel', 'ianhellfire', 'jyheffect', 'hellfireev', 'hellfireev', 'oversee', 'bitters', 'ggkeeponrockin', 'ggkeeponrockin', 'strawberrysoryu', 'zakuun', 'hoof', 'missiles', 'teeess', 'teeess', 'teeess', 'bypass', 'password', 'donjazzy', 'cuddlesforjen', 'slammed', 'jeep', 'cherokee', 'rickybonessxm', 'specially', 'allows', 'chowchilla', 'hijackerturnedsattutor', 'chills', 'cooper', 'jagexsupport', 'funtenna', 'coldblooded', 'bronville', 'vosloorus', 'skill', 'chilling', 'windowsill', 'herecnn', 'allinwithchris', 'mugged', 'trinna', 'mylittlepwnies', 'affiliation', 'mcconnell', 'mcconnell', 'mcconnell', 'hannahkauthor', 'freeamirnow', 'freeallfour', 'freeallfour', 'stood', 'surrender', 'quottelevision', 'massacre', 'ssu', 'meaningless', 'distress', 'peers', 'zepp', 'teddy', 'submitt', 'aviationaddicts', 'referred', 'referring', 'messed', 'zaynmaiikist', 'guillermo', 'noaa', 'looping', 'eggalie', 'hurricanedolce', 'hurricanedame', 'wireless', 'chubbysquirrel', 'chubbysquirrel', 'hurricanesurge', 'hurricanes', 'terrified', 'shootas', 'freegeezy', 'freegeezy', 'mixxtail', 'brittsand', 'hurricanetyphoon', 'hurricanetyphoon', 'pattonoswalt', 'momentdiarrhea', 'jeffersonanddoris', 'jeffersonanddoris', 'offenders', 'killedinjured', 'killers', 'rvacchianonydn', 'settle', 'fullback', 'scott', 'supporthealthhomebathroomsupportelderlyinjureds', 'supporthealthhomebathroomsupportelderlyinjureds', 'supporthealthhomebathroomsupportelderlyinjureds', 'supporthealthhomebathroomsupportelderlyinjureds', 'smugglers', 'shootoutåê', 'allegedly', 'thehammers', 'tonycottee', 'tonycottee', 'welles', 'forgottenaesop', 'effectiveness', 'effectiveness', 'tayiorrmade', 'possibly', 'regardless', 'creeping', 'attended', 'peel', 'likeavillasboas', 'professional', 'crossing', 'leonardville', 'buffoonmike', 'buffoonmike', 'thepartyofmeanness', 'thepartyofmeanness', 'carterville', 'dallascowboys', 'barring', 'joboozoso', 'sergiopiaggio', 'cuff', 'updatefollowiccrealckt', 'updatefollowiccrealckt', 'zimmer', 'jazzs', 'tennis', 'mcclain', 'follownflnews', 'mcfadden', 'jjdirty', 'greggmair', 'wheelsio', 'lennlen', 'ddnt', 'seattledot', 'seattletimes', 'applications', 'soggy', 'vzwsupport', 'assassinkpg', 'assassinkpg', 'commercials', 'bentossell', 'bentossell', 'yahoocare', 'commentes', 'kerri', 'sackville', 'mistresspip', 'mistress', 'allyinwondrland', 'bangladeshaffected', 'bangladeshflood', 'tonymcguinness', 'tonymcguinness', 'mraamirjavaid', 'teahivetweets', 'employee', 'hronlinetweets', 'staffing', 'depressed', 'ledofficial', 'sweets', 'pfft', 'bullshit', 'plummeting', 'petting', 'overflowwas', 'commencement', 'boots', 'mousse', 'ebb', 'avalanchesallah', 'hoodedu', 'fleetwood', 'fleetwood', 'dundee', 'pollster', 'toddstarnes', 'gotthard', 'alltime', 'knowitall', 'freebesieged', 'winning', 'effiedeans', 'sleeper', 'opposition', 'flashflood', 'landslideill', 'sunshineill', 'presssec', 'presssec', 'assholes', 'pantherattack', 'jamilazzaini', 'eleskaylee', 'jannellix', 'jannellix', 'breeder', 'skippygaming', 'cunayyh', 'dipping', 'massage', 'evaaasr', 'evaaasr', 'foothill', 'foothill', 'assumes', 'hmm', 'twoout', 'collins', 'dantwitty', 'unwarranted', 'footage', 'saysee', 'eyessee', 'eyessee', 'abbott', 'abbott', 'campbell', 'arrive', 'peacefully', 'tellyandi', 'tanstaafl', 'correlation', 'coldmpress', 'commiting', 'iit', 'logically', 'cannibalism', 'dffrntsgd', 'riceechrispies', 'royalcarribean', 'attempted', 'labelled', 'flgovscott', 'commit', 'yelllowheather', 'yelllowheather', 'billyhodge', 'debatequestionswewanttohear', 'horrendous', 'carlachamorros', 'trillac', 'greeting', 'creelyou', 'brainless', 'theatershooting', 'defendantmass', 'crossexam', 'tirelessly', 'libertygeek', 'kissing', 'dismisses', 'challenged', 'bettyfreedoms', 'bettyfreedoms', 'theeconomist', 'decisionsunless', 'massmurderer', 'victoriagittins', 'neanderrebel', 'dissuaded', 'libertybell', 'hillarymass', 'hillarymass', 'vaccine', 'blairmcdougall', 'commenting', 'massacreantioch', 'screening', 'texaschainsawmassacre', 'animallogic', 'smoothed', 'forgotten', 'rabaa', 'observedrememberrabaa', 'observedrememberrabaa', 'eileenmfl', 'shells', 'bloodbathtv', 'channel', 'eyewitnesses', 'daddy', 'becarefulharry', 'freddiedeboer', 'sousse', 'wellknown', 'oompahperiod', 'creepiest', 'stuckinbooks', 'hannemans', 'raynbowaffair', 'difference', 'nosurrender', 'bully', 'kissimmee', 'kissimmee', 'kissimmee', 'retweetfollow', 'retweetfollow', 'rtfollowbackgain', 'ferrell', 'ferrell', 'asburyparkpress', 'commences', 'bass', 'droppd', 'meelllttting', 'meelllttting', 'meelllttting', 'meelllttting', 'meelllttting', 'deepak', 'mattytalks', 'nashhmu', 'beccacaitlyn', 'seagull', 'aleisstokes', 'intelligencebar', 'crowdtappers', 'joinvroom', 'commoditiesåêare', 'uncontrollable', 'lemairelee', 'bullpen', 'bubble', 'warriorcord', 'harassed', 'connects', 'discusses', 'cossack', 'kiranahmedd', 'mutt', 'assertative', 'intelligence', 'hillaryclinton', 'callin', 'underwood', 'cochisecollege', 'cooperation', 'gunned', 'asses', 'sterlingscott', 'beetroot', 'beetroot', 'gemmasterful', 'doretts', 'dorret', 'marcholl', 'nennicook', 'nennicook', 'aitchkaycee', 'britishbakeoff', 'paulhollywood', 'paulhollywood', 'giggling', 'dorette', 'impressions', 'hazelannmac', 'bakeofffriends', 'bakeofffriends', 'backroom', 'physically', 'tatooed', 'pointless', 'addition', 'slipping', 'billion', 'professionally', 'professionally', 'overrun', 'booktubeathon', 'seamstress', 'jebbush', 'allowing', 'irannucleardeal', 'sweep', 'kennedys', 'disasterrelated', 'consciousness', 'err', 'finnish', 'gigawatts', 'installed', 'gwatt', 'fleet', 'willieami', 'justthebottle', 'justthebottle', 'cooling', 'lapping', 'gulls', 'sizewell', 'thegreenparty', 'puppyshogun', 'philippine', 'seemly', 'narcissism', 'richhomeydon', 'kneelbot', 'smaller', 'litter', 'mccainenl', 'stonewall', 'bbsp', 'assassins', 'assassins', 'mooniighthunty', 'mooniighthunty', 'jesuss', 'battleship', 'freshness', 'horiikawa', 'rizzo', 'damnnnn', 'damnnnn', 'damnnnn', 'accordingly', 'breemars', 'cnns', 'accept', 'zimmerman', 'rzimmermanjr', 'acc', 'stripped', 'strutted', 'batters', 'tt', 'sizygwwf', 'theevilolives', 'accustomed', 'kontrolled', 'canaanites', 'teamhennessy', 'teamhennessy', 'djeddygnj', 'ripping', 'lockewiggins', 'tiggr', 'kerry', 'imminent', 'smallbiz', 'quarrel', 'littledeath', 'gesserit', 'atgrannyshouse', 'kylewappler', 'deepwater', 'wattle', 'sydtraffic', 'trafficnetwork', 'spilled', 'wendell', 'berry', 'hannah', 'cityofkamloops', 'kamloops', 'legionnairesdisease', 'legionna', 'sebee', 'ffvii', 'ffvii', 'midweek', 'arreat', 'bills', 'soonpandemonium', 'khalidkkazi', 'faceless', 'bennycapricon', 'drbaseball', 'granttamane', 'drewwtaylor', 'hillside', 'shestooyoung', 'carefully', 'pbohanna', 'justaguess', 'differ', 'godlookrunning', 'godlookrunning', 'autismawareness', 'jesse', 'suffers', 'timmicallef', 'timmicallef', 'welladjusted', 'driverreplace', 'cardheaddesk', 'eyeball', 'herrelax', 'montetjwitter', 'nutsandboltssp', 'teena', 'darrylbrooks', 'darrylbrooks', 'biggangvh', 'dressed', 'attic', 'collar', 'quotesttg', 'dirknomissski', 'dirknomissski', 'shook', 'ianbartlett', 'adumbbb', 'adumbbb', 'debbie', 'submitting', 'redeemer', 'hurry', 'jeannathomas', 'freeman', 'worrying', 'boot', 'billy', 'queensland', 'aåêmiddleaged', 'dccc', 'dccc', 'mmfa', 'vinnie', 'interracial', 'harrowing', 'harassment', 'georgegalloway', 'gallowaymayor', 'liverpool', 'stree', 'robbiewilliams', 'robbiewilliams', 'asswipe', 'milwaukee', 'slosheriff', 'onlinecommunities', 'amageddon', 'freespeech', 'freespeech', 'offensive', 'communities', 'aannnnd', 'aannnnd', 'aannnnd', 'aannnnd', 'offensiveåêcontent', 'huffman', 'missambear', 'reddits', 'subreddits', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'scrambledeggs', 'caseedward', 'gmtty', 'mhtwfnetofficials', 'bathroomits', 'wipp', 'northwestproof', 'offsite', 'emittin', 'ccot', 'capeann', 'seagulls', 'triciaoneill', 'triciaoneillphoto', 'myrtlegroggins', 'aandb', 'jimmy', 'bebacksoon', 'nathanfillion', 'lizzie', 'floodrainstorm', 'kooks', 'deadgrassandflowers', 'petereallen', 'huffpostuk', 'bbclive', 'zippednews', 'vassalboro', 'justmarried', 'freedomoutpost', 'refugeesvictimiserdutton', 'refugeesvictimiserdutton', 'evangelicalliarabbott', 'evangelicalliarabbott', 'evangelicalliarabbott', 'choppergatebronwynbishopauspol', 'cameroon', 'foods', 'reaad', 'plsss', 'plsss', 'connections', 'tonyabbottmhr', 'tonyabbottmhr', 'marrie', 'redcliffe', 'flee', 'feeds', 'dutton', 'presser', 'newbeginningsanimalrescue', 'ppact', 'racco', 'suggs', 'sammy', 'floodzone', 'raheel', 'summervibes', 'pioneer', 'enkelbiljett', 'menolippu', 'smugglersåênabbed', 'smugglersåênabbed', 'romanatwoodvlogs', 'kittens', 'brittanypetko', 'hiatt', 'ribbon', 'offtrackhorse', 'onegreenplanet', 'vessel', 'tconnellyr', 'tconnellyr', 'mediterran', 'carr', 'childhooddefined', 'childhooddefined', 'roddypiperautos', 'carryi', 'allergic', 'flatts', 'hasåêarrived', 'daysweeks', 'booth', 'kappa', 'acaciapenn', 'shidddd', 'shidddd', 'shidddd', 'abrancaballero', 'careerbest', 'ullman', 'teemo', 'bytorrecilla', 'bytorrecilla', 'torrecilla', 'torrecilla', 'ally', 'ricotta', 'stephanenny', 'trollkrattos', 'trollkrattos', 'championsblackfoot', 'sweetpeas', 'allotment', 'vitesse', 'supporters', 'freeview', 'happiness', 'happiness', 'discuss', 'dee', 'andmillions', 'bhramabull', 'socially', 'wee', 'ryleedowns', 'aelinrhee', 'nffc', 'halljh', 'hooligan', 'insurersmillions', 'faafa', 'rubble', 'churchill', 'crazyideascollege', 'bulls', 'betting', 'diggin', 'lookg', 'tnn', 'yycwalks', 'prodding', 'okgabby', 'carpooling', 'sorrybutitstrue', 'yuppies', 'unhappy', 'lookss', 'lookss', 'savannahross', 'savannahross', 'terrific', 'bleed', 'foo', 'freezerdummy', 'freezerdummy', 'conormidd', 'greedy', 'fullscreen', 'fullscreen', 'vanessa', 'reboot', 'odell', 'swallowed', 'woo', 'hoo', 'booze', 'globiinclusion', 'nrcmiddleeast', 'nrcmiddleeast', 'zaatari', 'betweensong', 'woodlandms', 'villicanaalicia', 'villicanaalicia', 'daggers', 'jammed', 'grabbed', 'zamtriossu', 'offside', 'mommys', 'brooke', 'wwa', 'realliampayne', 'addtexastonextdtour', 'emmachosenone', 'jessienovoarp', 'jessienovoa', 'toddyrockstar', 'mannequin', 'camilacabello', 'externally', 'bizzlemahomie', 'estellasrevenge', 'smelltaste', 'lhh', 'harshness', 'abetter', 'spree', 'stvmlly', 'safferoonicle', 'safferoonicle', 'yell', 'funnydadcoach', 'missdaoh', 'kamkasteiiano', 'nochilllukehammingsim', 'nochilllukehammingsim', 'nochilllukehammingsim', 'ahhhh', 'ahhhh', 'ahhhh', 'omgggg', 'omgggg', 'omgggg', 'danemillar', 'jaileens', 'pillows', 'muffle', 'uhmmm', 'uhmmm', 'robbed', 'attached', 'casually', 'sakuuchiha', 'lawsonofficial', 'followed', 'dell', 'ollymursaus', 'appropriation', 'buddhas', 'looney', 'griffin', 'schoolokim', 'queenwendy', 'aaaa', 'aaaa', 'aaaa', 'lemme', 'roomr', 'oppose', 'hebrooon', 'hebrooon', 'summary', 'channels', 'toss', 'padded', 'offing', 'clegg', 'vessels', 'offshore', 'seeks', 'dogger', 'cgg', 'oddball', 'oddball', 'ifunny', 'manually', 'coop', 'swallows', 'occasionb', 'trolley', 'accidentalprophecy', 'moorlandschmbr', 'depression', 'evansville', 'davidcovucci', 'unhappiness', 'unhappiness', 'snapping', 'abbandoned', 'castello', 'currency', 'transgress', 'onnnn', 'onnnn', 'onnnn', 'wooden', 'appease', 'att', 'wccorosen', 'lloyds', 'slipper', 'aroundyoull', 'seeyou', 'esse', 'wonderfully', 'installment', 'edsheeran', 'corii', 'aar', 'bonnieg', 'ibeyiofficial', 'horrormoviesca', 'demoness', 'ss', 'marriedfoxysiren', 'jennifer', 'dull', 'process', 'smithereens', 'queenmy', 'vvorm', 'soonermagic', 'fevwarrior', 'screeching', 'accompanying', 'attila', 'utcmillcityio', 'dangdaddy', 'thinner', 'kiroseattle', 'dill', 'winner', 'iinet', 'buffering', 'cancelled', 'abceyewitness', 'howell', 'lloyd', 'brooo', 'brooo', 'collie', 'buddz', 'hmmm', 'hmmm', 'selling', 'sammysosita', 'ciggs', 'trynna', 'billmccabe', 'billmccabe', 'smells', 'bremorrow', 'mentaltwitter', 'teamatowinner', 'commas', 'accuracy', 'chann', 'footed', 'sorryi', 'rtirishirrmchapmanwsaz', 'wsazbrittany', 'kellyannwx', 'kellyannwx', 'sassy', 'ibooklove', 'bookboost', 'bookboost', 'treeporn', 'moonlight', 'lalaloopsy', 'dolls', 'seed', 'habbo', 'battleships', 'matchwood', 'dirktrossen', 'freddie', 'sippin', 'wheelers', 'amssummer', 'amssummer', 'pyrbliss', 'longll', 'treescape', 'takeoff', 'uncommon', 'lakeeffect', 'lakeeffect', 'twill', 'ûïsippin', 'effective', 'adweek', 'gamefeed', 'trooper', 'bobble', 'saat', 'jenniferarri', 'jenniferarri', 'comeeeee', 'comeeeee', 'comeeeee', 'comeeeee', 'stormfree', 'happenings', 'hobby', 'lobby', 'hawaiianpaddlesports', 'hawaiianpaddlesports', 'pillow', 'mypillowstudio', 'johngreen', 'finna', 'boutta', 'nasahurricane', 'satellite', 'lesleymariiee', 'lesleymariiee', 'greet', 'bliss', 'hanomottola', 'rexyy', 'danielle', 'ouwbball', 'ouwbball', 'engineering', 'witter', 'freeze', 'veggies', 'fleek', 'stressing', 'mxaaaa', 'mxaaaa', 'mxaaaa', 'niqqa', 'kidicalmassdc', 'correcting', 'excessive', 'weakness', 'kpcc', 'nafeezahmed', 'shortfalls', 'sabcnewsroom', 'deeply', 'illegality', 'leashless', 'steelthe', 'illogicalthe', 'committing', 'committing', 'llll', 'llll', 'llll', 'explosivesrigged', 'josephjett', 'aseer', 'bbclaurak', 'reoccur', 'daisycuttertz', 'lessons', 'sonofbobbob', 'shimmyfab', 'chopping', 'rooftops', 'offshoot', 'offshoot', 'rebecca', 'egged', 'saadthe', 'kppolice', 'confesses', 'middleeasteye', 'middleeasteye', 'muzzies', 'barracks', 'peeped', 'jeepåêsunk', 'shattered', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'marr', 'untameddirewolf', 'benaffleck', 'mraffleck', 'arrestpastornganga', 'collaborating', 'lonelyness', 'depressing', 'prosser', 'mihirssharma', 'bonhomme', 'giannis', 'reef', 'offspring', 'lucypalladino', 'classes', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'thruuu', 'thruuu', 'tootrue', 'dorrian', 'affiliate', 'thomassmonson', 'wildlooking', 'reclusebetrayedbooks', 'mochichiiiii', 'mochichiiiii', 'mochichiiiii', 'mochichiiiii', 'ddnewslive', 'adriennetomah', 'clueless', 'driverless', 'driverlesscars', 'taaylordarr', 'taaylordarr', 'thesmallclark', 'trigger', 'rjkrraj', 'sessions', 'addiction', 'chronicillness', 'chronicillness', 'zoom', 'duchovbutt', 'starbuckscully', 'davidduchovny', 'plotted', 'ûïbbcwomanshour', 'coppednews', 'mithitennis', 'ghetto', 'narrated', 'glenn', 'stemming', 'arizzo', 'truthnewsbbccnnislamtruthgodisisterrorismquranlies', 'truthnewsbbccnnislamtruthgodisisterrorismquranlies', 'truthnewsbbccnnislamtruthgodisisterrorismquranlies', 'truthnewsbbccnnislamtruthgodisisterrorismquranlies', 'phillips', 'ldnrterrorists', 'crossborder', 'counterterrorism', 'fightåêterrorism', 'muslimsterrorismor', 'chattanoga', 'alliance', 'assad', 'appraisal', 'antiterrorism', 'officialmqm', 'mohammed', 'quizzed', 'warra', 'jammu', 'swiftycommissh', 'swiftycommissh', 'immortaltech', 'killin', 'mccains', 'whoops', 'stopping', 'keepingtheviginaclean', 'threatconnect', 'kinggerudo', 'ûïall', 'dmassa', 'illusoria', 'bloodbound', 'kristyleemusic', 'buddys', 'cooperstown', 'driller', 'torrential', 'soothmyslumber', 'watermeloann', 'thewebbeffect', 'thewebbeffect', 'weebly', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'essenceofme', 'gloomy', 'lorr', 'beenghosting', 'penny', 'fforecastthu', 'fforecastthu', 'russellville', 'russellville', 'russellville', 'clarksville', 'dardanelle', 'vivaargentina', 'soonergrunt', 'brrookkllyynnr', 'brrookkllyynnr', 'brrookkllyynnr', 'brrookkllyynnr', 'brrookkllyynnr', 'brrookkllyynnr', 'thebookclub', 'belle', 'kunalkapoor', 'sparxxx', 'sparxxx', 'threesome', 'brunette', 'heller', 'villa', 'giselle', 'cbcca', 'toocodtodd', 'toocodtodd', 'wyattb', 'maaaaan', 'maaaaan', 'maaaaan', 'maaaaan', 'collective', 'sorrowful', 'platt', 'toiindianews', 'commons', 'itssselenaluna', 'itssselenaluna', 'marriage', 'gunning', 'hirochii', 'bella', 'homessponsorships', 'innit', 'prettyboyshyflizzy', 'prettyboyshyflizzy', 'beautifully', 'starring', 'tween', 'battleroyalemod', 'billionaires', 'holly', 'hollyw', 'dramaallama', 'dramaallama', 'lilourry', 'zarry', 'narry', 'addicts', 'nissannews', 'nissannews', 'raabchar', 'affliction', 'communicate', 'saalon', 'cannabis', 'oppressed', 'oppressed', 'unaddressed', 'unaddressed', 'randallpinkston', 'foamcc', 'partially', 'simmering', 'concussion', 'pioneerpress', 'pioneerpress', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'jamiegriff', 'spell', 'annmarieronan', 'niamhosullivanx', 'yessum', 'viennabutcher', 'livagotta', 'hogging', 'megancoopy', 'brookesddl', 'brookesddl', 'hopped', 'afrikaan', 'smoakqueen', 'jusstdoitgirl', 'happing', 'annajhm', 'strawberries', 'buffetts', 'buffetts', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'troubleniallhariss', 'troubleniallhariss', 'nikki', 'charleyisqueen', 'egg', 'kerrykatona', 'stunningly', 'princeoffencing', 'matthew', 'donnelly', 'donnelly', 'freefromwolves', 'danny', 'baan', 'bbshelli', 'bbshelli', 'illusion', 'speech', 'dvbbs', 'arceen', 'ripples', 'eyesss', 'eyesss', 'youuu', 'youuu', 'greenlacey', 'russell', 'russell', 'sweeps', 'awayyoure', 'telly', 'titty', 'tittie', 'ellenfromnowon', 'toosoon', 'toosoon', 'briannafrost', 'carolinagutierr', 'woodchucks', 'boost', 'gg', 'llegaste', 'dolla', 'potter', 'breed', 'thebuffshow', 'twisterlovesshania', 'repped', 'jrlallo', 'narrator', 'chemically', 'landfall', 'territory', 'bullseye', 'yygb', 'mhtwfnetthousands', 'buddha', 'chestertweetsuk', 'aladdin', 'kettlebell', 'kettlebell', 'stresses', 'battered', 'uprooting', 'commandi', 'itthey', 'disappears', 'freedoma', 'swell', 'stirring', 'belligerent', 'iateyourfood', 'uprootin', 'belly', 'maailiss', 'maailiss', 'sixpenceee', 'sixpenceee', 'volcanoåêinåêrussia', 'gtii', 'ronnie', 'mrmikeeaton', 'kiddos', 'jj', 'kenneth', 'indecisiveness', 'lexipurduee', 'dpagexxi', 'thuggin', 'raccoons', 'raccoons', 'littlewomenla', 'thugging', 'robertoneill', 'xii', 'cutter', 'muttatek', 'kwwwkwwwk', 'kwwwkwwwk', 'kwwwkwwwk', 'kwwwkwwwk', 'camilla', 'shatter', 'choppas', 'thatrussianman', 'splatoon', 'splattershot', 'snazzychipz', 'lolook', 'needing', 'lcc', 'bloggers', 'ineedexposure', 'dannyonpc', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'supporting', 'corruption', 'ddos', 'cheyenne', 'bookmobile', 'opposed', 'kirstiealley', 'arranged', 'submissions', 'piss', 'itill', 'cramming', 'affair', 'millennium', 'millennium', 'attending', 'standstill', 'lucymayofficial', 'scissor', 'alexhammerstone', 'kttape', 'theemobrago', 'yelled', 'summerhallery', 'summerhallery', 'midsummer', 'cantwaittoplayinminneapolis', 'cantwaittoplayinminneapolis', 'amazingness', 'finall', 'harris', 'riooooos', 'riooooos', 'riooooos', 'riooooos', 'jennife', 'cnni', 'uncontrolled', 'connecticut', 'ariaahrary', 'martsunmushroom', 'profittothepeople', 'doessnt', 'effected', 'fingerrockfire', 'sheet', 'mattkroschel', 'lastingness', 'thebachelorette', 'niiiice', 'niiiice', 'niiiice', 'vhull', 'odeekiti', 'hardball', 'lees', 'battleanother', 'umbrella', 'flipped', 'calmstillness', 'calmstillness', 'leelanau', 'windstormfollow', 'jeez', 'approves', 'association', 'retooled', 'retirees', 'handicapped', 'fatally', 'biggar', 'phillip', 'exaggerated', 'asterpuppet', 'assured', 'officerrelated', 'officerrelated', 'wwp', 'aandw', 'chesttorso', 'kerricktrial', 'jonathanferrell', 'jonathanferrell', 'charlesdagnall', 'rubbin', 'endoccupation', 'freekashmir', 'mirrors', 'dianneg', 'bullet', 'selfesteem', 'ferrells', 'ferrells', 'mattmosley', 'woodlawn', 'scrolling', 'session', 'discussing', 'friggin', 'dabbed', 'sorrower', 'captainnmorgan', 'gazette', 'memenaar', 'icequeenfroslas', 'progressives', 'woodward', 'shoalstraffic', 'misscharleywebb', 'misscharleywebb', 'greer', 'janeenorman', 'buzzfeed', 'buzzfeed', 'malaysiaairlines', 'yahoonewsdigest', 'rossmartin', 'oliviaapalmerr', 'oliviaapalmerr', 'tuneswgg', 'ohmyjoshh', 'stevenrulles', 'riddler', 'barra', 'widda', 'jtruff', 'gameofkittens', 'explodingkittens', 'ayyo', 'fatherofthree']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckk28MS65zPr",
        "outputId": "575ed790-9646-4d40-e32d-f3aaddccc1f2"
      },
      "source": [
        "Consec_3_letter_words = []\r\n",
        "for word in word_corpus:\r\n",
        "  for idx, char in enumerate(word):\r\n",
        "    if idx + 2 < len(word):\r\n",
        "      if word[idx] == word[idx + 1] == word[idx + 2]:\r\n",
        "        Consec_3_letter_words.append(word)\r\n",
        "print(len(Consec_3_letter_words))\r\n",
        "print(Consec_3_letter_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196\n",
            "['soooo', 'soooo', 'awwww', 'awwww', 'mhmmm', 'alexshipppp', 'alexshipppp', 'avysss', 'aiii', 'baaaack', 'baaaack', 'iii', 'xdojjjj', 'xdojjjj', 'omgbethersss', 'xxx', 'grrrr', 'grrrr', 'wwwbigbaldhead', 'zzzz', 'zzzz', 'lmfaoooo', 'lmfaoooo', 'deeeznvtzzz', 'deeeznvtzzz', 'oooureli', 'mmm', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'uhhhhh', 'uhhhhh', 'uhhhhh', 'ieee', 'rokiieee', 'loveyouuuu', 'loveyouuuu', 'sooo', 'michelleellle', 'emaaalay', 'crosssectarian', 'naaa', 'kwaaaaadead', 'kwaaaaadead', 'kwaaaaadead', 'ssshhheeesshh', 'ssshhheeesshh', 'ssshhheeesshh', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'shoook', 'frackfreeeu', 'stiiilo', 'ahhhhh', 'ahhhhh', 'ahhhhh', 'alllivesmatter', 'ohyayyyyay', 'ohyayyyyay', 'ayyy', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'ssssnell', 'ssssnell', 'www', 'iiii', 'iiii', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'jeesss', 'milioooo', 'milioooo', 'roomsgrrrr', 'roomsgrrrr', 'fireiii', 'alllll', 'alllll', 'alllll', 'ûahhh', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'wompppp', 'wompppp', 'eeenice', 'justinejayyy', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'edvinnn', 'adorableappple', 'thankkk', 'errrr', 'errrr', 'lmfaooo', 'annddd', 'heebsterrr', 'teeess', 'presssec', 'evaaasr', 'yelllowheather', 'meelllttting', 'meelllttting', 'bakeofffriends', 'damnnnn', 'damnnnn', 'dirknomissski', 'adumbbb', 'dccc', 'aannnnd', 'aannnnd', 'aaarrrgghhh', 'aaarrrgghhh', 'aaarrrgghhh', 'plsss', 'shidddd', 'shidddd', 'nochilllukehammingsim', 'ahhhh', 'ahhhh', 'omgggg', 'omgggg', 'uhmmm', 'aaaa', 'aaaa', 'hebrooon', 'onnnn', 'onnnn', 'brooo', 'hmmm', 'comeeeee', 'comeeeee', 'comeeeee', 'mxaaaa', 'mxaaaa', 'llll', 'llll', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'thruuu', 'mochichiiiii', 'mochichiiiii', 'mochichiiiii', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sparxxx', 'maaaaan', 'maaaaan', 'maaaaan', 'itssselenaluna', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'eyesss', 'youuu', 'sixpenceee', 'kwwwkwwwk', 'kwwwkwwwk', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'riooooos', 'riooooos', 'riooooos', 'niiiice', 'niiiice']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuBxMrlD6Qrs",
        "outputId": "7ce89146-039e-4f38-a726-230cc4aa5d20"
      },
      "source": [
        "Consec_4_letter_words = []\r\n",
        "for word in word_corpus:\r\n",
        "  for idx, char in enumerate(word):\r\n",
        "    if idx + 3 < len(word):\r\n",
        "      if word[idx] == word[idx + 1] == word[idx + 2] == word[idx + 3]:\r\n",
        "        Consec_4_letter_words.append(word)\r\n",
        "print(len(Consec_4_letter_words))\r\n",
        "print(Consec_4_letter_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n",
            "['soooo', 'awwww', 'alexshipppp', 'baaaack', 'xdojjjj', 'grrrr', 'zzzz', 'lmfaoooo', 'sniiiiiiff', 'sniiiiiiff', 'sniiiiiiff', 'uhhhhh', 'uhhhhh', 'loveyouuuu', 'kwaaaaadead', 'kwaaaaadead', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'pusssssssssy', 'ahhhhh', 'ahhhhh', 'ohyayyyyay', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'aaaaaaallll', 'ssssnell', 'iiii', 'riveeeeeer', 'riveeeeeer', 'riveeeeeer', 'milioooo', 'roomsgrrrr', 'alllll', 'alllll', 'nowwwwww', 'nowwwwww', 'nowwwwww', 'wompppp', 'selmoooooo', 'selmoooooo', 'selmoooooo', 'errrr', 'damnnnn', 'aannnnd', 'shidddd', 'ahhhh', 'omgggg', 'aaaa', 'onnnn', 'comeeeee', 'comeeeee', 'mxaaaa', 'llll', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'blaaaaaaa', 'ayhhhhhdjjfjrjjrdjjeks', 'ayhhhhhdjjfjrjjrdjjeks', 'mochichiiiii', 'mochichiiiii', 'sheetingaaaaaand', 'sheetingaaaaaand', 'sheetingaaaaaand', 'maaaaan', 'maaaaan', 'ruddyyyyyy', 'ruddyyyyyy', 'ruddyyyyyy', 'caaaaaall', 'caaaaaall', 'caaaaaall', 'wooooooo', 'wooooooo', 'wooooooo', 'wooooooo', 'riooooos', 'riooooos', 'niiiice']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0dVxQ866d-a",
        "outputId": "8b8ba5a1-42ef-418e-f88a-a7937e193523"
      },
      "source": [
        "Consec_4_wr_letter_words = []\r\n",
        "for word in Consec_4_letter_words:\r\n",
        "  new_word = ''\r\n",
        "  for idx, char in enumerate(word):\r\n",
        "    if idx + 1 < len(word):\r\n",
        "      \r\n",
        "      if word[idx] != word[idx + 1]:\r\n",
        "        # print(word[idx], word[idx + 1])\r\n",
        "        new_word = new_word + char\r\n",
        "    else:\r\n",
        "      # if word[idx - 1] == word[idx]:\r\n",
        "      new_word = new_word + char\r\n",
        "  Consec_4_wr_letter_words.append(new_word)\r\n",
        "        \r\n",
        "print(len(Consec_4_wr_letter_words))\r\n",
        "print(Consec_4_wr_letter_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84\n",
            "['so', 'aw', 'alexship', 'back', 'xdoj', 'gr', 'z', 'lmfao', 'snif', 'snif', 'snif', 'uh', 'uh', 'loveyou', 'kwadead', 'kwadead', 'pusy', 'pusy', 'pusy', 'pusy', 'pusy', 'pusy', 'ah', 'ah', 'ohyayay', 'al', 'al', 'al', 'al', 'al', 'snel', 'i', 'river', 'river', 'river', 'milio', 'romsgr', 'al', 'al', 'now', 'now', 'now', 'womp', 'selmo', 'selmo', 'selmo', 'er', 'damn', 'and', 'shid', 'ah', 'omg', 'a', 'on', 'come', 'come', 'mxa', 'l', 'bla', 'bla', 'bla', 'bla', 'ayhdjfjrjrdjeks', 'ayhdjfjrjrdjeks', 'mochichi', 'mochichi', 'shetingand', 'shetingand', 'shetingand', 'man', 'man', 'rudy', 'rudy', 'rudy', 'cal', 'cal', 'cal', 'wo', 'wo', 'wo', 'wo', 'rios', 'rios', 'nice']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BuU0m9d-MEe",
        "outputId": "7c1457ee-08b2-471e-d4ea-1fe50b41a56c"
      },
      "source": [
        "from collections import Counter\r\n",
        "\r\n",
        "new_words = Counter(Consec_4_wr_letter_words)\r\n",
        "\r\n",
        "for j, i in new_words.items():\r\n",
        "  print(j, i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "so 1\n",
            "aw 1\n",
            "alexship 1\n",
            "back 1\n",
            "xdoj 1\n",
            "gr 1\n",
            "z 1\n",
            "lmfao 1\n",
            "snif 3\n",
            "uh 2\n",
            "loveyou 1\n",
            "kwadead 2\n",
            "pusy 6\n",
            "ah 3\n",
            "ohyayay 1\n",
            "al 7\n",
            "snel 1\n",
            "i 1\n",
            "river 3\n",
            "milio 1\n",
            "romsgr 1\n",
            "now 3\n",
            "womp 1\n",
            "selmo 3\n",
            "er 1\n",
            "damn 1\n",
            "and 1\n",
            "shid 1\n",
            "omg 1\n",
            "a 1\n",
            "on 1\n",
            "come 2\n",
            "mxa 1\n",
            "l 1\n",
            "bla 4\n",
            "ayhdjfjrjrdjeks 2\n",
            "mochichi 2\n",
            "shetingand 3\n",
            "man 2\n",
            "rudy 3\n",
            "cal 3\n",
            "wo 4\n",
            "rios 2\n",
            "nice 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6H4W2BLrPPJ"
      },
      "source": [
        "#Sub program list of chat language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16TRNS7_rO4p",
        "outputId": "c0b35a22-f465-4807-9e69-35f9801168bb"
      },
      "source": [
        "word_corpus = []\r\n",
        "j = 0\r\n",
        "for tweet in Tweets_PreProcessed['tokenized_processed']:\r\n",
        "  for word in tweet:\r\n",
        "    if word in word_corpus:\r\n",
        "      j = j +1\r\n",
        "    else:\r\n",
        "      word_corpus.append(word)\r\n",
        "print(len(word_corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_tFc1LrbpB",
        "outputId": "cbdeb0e9-80ea-43c5-b4da-ef7195db327f"
      },
      "source": [
        "two_letter_words = []\r\n",
        "\r\n",
        "for word in word_corpus:\r\n",
        "  if len(word) == 2:\r\n",
        "    two_letter_words.append(word)\r\n",
        "print((two_letter_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['of', 'us', 'la', 'to', 'in', 'by', 'no', 'or', 'as', 'am', 'on', 'an', 'is', 'so', 'do', 'we', 'up', 'my', 'rt', 'me', 'at', 'it', 'ûò', 'ûó', 'st', 'ig', 'fb', 'be', 'if', 'wm', 'en', 'go', 'nb', 'rd', 'pm', 'av', 'sb', 'sr', 'dr', 'th', 'nc', 'ps', 'ir', 'xb', 'tc', 'bb', 'eu', 'hu', 'cr', 'ca', 'ok', 'ny', 'he', 'ûï', 'em', 'un', 'bc', 'lg', 'vs', 'az', 'oh', 'vi', 'mo', 'xv', 'gt', 'xp', 'cd', 'el', 'ww', 'pd', 'eh', 'tv', 'ki', 'ìñ', 'da', 'mc', 'bk', 'ii', 'pt', 'ik', 'xl', 'px', 'lt', 'yo', 'wd', 'nd', 'ya', 'tb', 'du', 'dc', 'id', 'ft', 'gm', 'll', 'gh', 'dj', 'bu', 'ms', 'fm', 'rn', 'gf', 'ch', 'pl', 're', 'mb', 'te', 'hw', 'tf', 'ty', 'rq', 'ye', 'au', 'dq', 'hi', 'lb', 'pc', 'sg', 'ah', 've', 'bp', 'se', 'bs', 'ga', 'rs', 'ur', 'ee', 'ra', 'al', 'ìü', 'jp', 'br', 'ep', 'po', 'es', 'va', 'js', 'mf', 'yr', 'wr', 'ri', 'mp', 'ed', 'et', 'co', 'nh', 'uh', 'fr', 'vc', 'rl', 'er', 'pp', 'mv', 'bg', 'ov', 'åç', 'åè', 'sf', 'nu', 'md', 'ha', 'ââ', 'sa', 'sl', 'wi', 'bd', 'ks', 'åê', 'eb', 'ag', 'fe', 'eo', 'mm', 'cs', 'mi', 'ux', 'uk', 'fd', 'tt', 'sh', 'mh', 'km', 'fi', 'di', 'de', 'sk', 'ne', 'cj', 'ds', 'wp', 'na', 'wy', 'af', 'np', 'ar', 'yh', 'rì', 'wa', 'ce', 'kp', 'xd', 'oz', 'bo', 'mr', 'ex', 'bn', 'sw', 'ls', 'mt', 'sq', 'si', 'dw', 'ib', 'uv', 'hd', 'sj', 'kc', 'fn', 'ut', 'cn', 'aw', 'tw', 'lv', 'ci', 'ko', 'ma', 'yy', 'wo', 'cw', 'ja', 'ke', 'nm', 'nv', 'ev', 'ns', 'eq', 'ml', 'sm', 'gp', 'aa', 'ac', 'jr', 'dt', 'ak', 'yc', 'fc', 'nw', 'tx', 'ap', 'ie', 'hl', 'gc', 'tr', 'zf', 'oo', 'pb', 'tn', 'dk', 'sp', 'dm', 'sn', 'ss', 'mk', 'gd', 'mn', 'rp', 'ho', 'rg', 'fl', 'jk', 'ky', 'wx', 'vv', 'cm', 'nj', 'nf', 'lk', 'sd', 'cc', 'dl', 'gv', 'os', 'db', 'su', 'ts', 'pg', 'ad', 'yu', 'mx', 'ba', 'rb', 'wk', 'hr', 'nl', 'op', 'ip', 'ol', 'df', 'kg', 'ay', 'cl', 'hc', 'oi', 'fo', 'hs', 'dh', 'hm', 'iw', 'ln', 'oc', 'ud', 'fu', 'gr', 'lh', 'ey', 'mw', 'ru', 'um', 'tj', 'lu', 'td', 'wc', 'xo', 'cv', 'rv', 'nz', 'tu', 'gb', 'ly', 'ef', 'gi', 'jj', 'ct', 'ab', 'fa', 'wn', 'pa', 'hq', 'ij', 'fx']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzhFcKLNlwFr"
      },
      "source": [
        "#Other features to be tried"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3P_TpXGly-C"
      },
      "source": [
        "# To remove leading and ending spaces\r\n",
        "\r\n",
        "text = text.strip()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}